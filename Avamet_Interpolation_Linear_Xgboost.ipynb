{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadoonhammad/avamet-data/blob/main/Avamet_Interpolation_Linear_Xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55UKMEywcJtc"
      },
      "outputs": [],
      "source": [
        "pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ4rhiynGnBq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from os import listdir\n",
        "from io import StringIO\n",
        "from os.path import join\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "import plotly.express as px\n",
        "from plotly.io import write_image\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jZwvLizkrUQ"
      },
      "source": [
        "# Values in missing interval\n",
        "\n",
        "Before data imputation, it is important to calculate the length of consecutive missing values in each dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "nQCfK2qmtGX0",
        "outputId": "89318768-d222-407d-d642-173d7baaa65e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"missing_all\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          8,\n          13,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name_21\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"c02m042e03_2021.csv\",\n          \"c03m093e04_2021.csv\",\n          \"c02m051e03_2021.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_values_21\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 671,\n        \"min\": 6,\n        \"max\": 3152,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          210,\n          7,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name_22\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"c02m042e03_2022.csv\",\n          \"c03m093e04_2022.csv\",\n          \"c02m051e03_2022.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_values_22\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1348,\n        \"min\": 6,\n        \"max\": 6671,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          6,\n          7,\n          750\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name_23\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"c02m042e03_2023.csv\",\n          \"c03m093e04_2023.csv\",\n          \"c02m051e03_2023.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_values_23\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 469,\n        \"min\": 7,\n        \"max\": 1977,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          99,\n          1977,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "missing_all"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-609cd969-d370-4f6f-9695-e21c1648f460\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file_name_21</th>\n",
              "      <th>missing_values_21</th>\n",
              "      <th>file_name_22</th>\n",
              "      <th>missing_values_22</th>\n",
              "      <th>file_name_23</th>\n",
              "      <th>missing_values_23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>c01m045e01_2021.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c01m045e01_2022.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c01m045e01_2023.csv</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>c01m061e01_2021.csv</td>\n",
              "      <td>228</td>\n",
              "      <td>c01m061e01_2022.csv</td>\n",
              "      <td>875</td>\n",
              "      <td>c01m061e01_2023.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>c01m080e01_2021.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c01m080e01_2022.csv</td>\n",
              "      <td>246</td>\n",
              "      <td>c01m080e01_2023.csv</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>c01m083e01_2021.csv</td>\n",
              "      <td>12</td>\n",
              "      <td>c01m083e01_2022.csv</td>\n",
              "      <td>23</td>\n",
              "      <td>c01m083e01_2023.csv</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>c01m127e01_2021.csv</td>\n",
              "      <td>406</td>\n",
              "      <td>c01m127e01_2022.csv</td>\n",
              "      <td>204</td>\n",
              "      <td>c01m127e01_2023.csv</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>c01m141e01_2021.csv</td>\n",
              "      <td>241</td>\n",
              "      <td>c01m141e01_2022.csv</td>\n",
              "      <td>7</td>\n",
              "      <td>c01m141e01_2023.csv</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>c02m026e02_2021.csv</td>\n",
              "      <td>17</td>\n",
              "      <td>c02m026e02_2022.csv</td>\n",
              "      <td>1419</td>\n",
              "      <td>c02m026e02_2023.csv</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>c02m042e02_2021.csv</td>\n",
              "      <td>483</td>\n",
              "      <td>c02m042e02_2022.csv</td>\n",
              "      <td>215</td>\n",
              "      <td>c02m042e02_2023.csv</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>c02m042e03_2021.csv</td>\n",
              "      <td>1147</td>\n",
              "      <td>c02m042e03_2022.csv</td>\n",
              "      <td>6671</td>\n",
              "      <td>c02m042e03_2023.csv</td>\n",
              "      <td>1504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>c02m051e03_2021.csv</td>\n",
              "      <td>210</td>\n",
              "      <td>c02m051e03_2022.csv</td>\n",
              "      <td>8</td>\n",
              "      <td>c02m051e03_2023.csv</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>c02m119e02_2021.csv</td>\n",
              "      <td>694</td>\n",
              "      <td>c02m119e02_2022.csv</td>\n",
              "      <td>2349</td>\n",
              "      <td>c02m119e02_2023.csv</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>c03m034e01_2021.csv</td>\n",
              "      <td>3152</td>\n",
              "      <td>c03m034e01_2022.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c03m034e01_2023.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>c03m070e01_2021.csv</td>\n",
              "      <td>73</td>\n",
              "      <td>c03m070e01_2022.csv</td>\n",
              "      <td>750</td>\n",
              "      <td>c03m070e01_2023.csv</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>c03m093e04_2021.csv</td>\n",
              "      <td>20</td>\n",
              "      <td>c03m093e04_2022.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c03m093e04_2023.csv</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>c03m096e01_2021.csv</td>\n",
              "      <td>1457</td>\n",
              "      <td>c03m096e01_2022.csv</td>\n",
              "      <td>8</td>\n",
              "      <td>c03m096e01_2023.csv</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>c03m102e01_2021.csv</td>\n",
              "      <td>61</td>\n",
              "      <td>c03m102e01_2022.csv</td>\n",
              "      <td>7</td>\n",
              "      <td>c03m102e01_2023.csv</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>c03m121e01_2021.csv</td>\n",
              "      <td>833</td>\n",
              "      <td>c03m121e01_2022.csv</td>\n",
              "      <td>43</td>\n",
              "      <td>c03m121e01_2023.csv</td>\n",
              "      <td>1977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>c04m122e01_2021.csv</td>\n",
              "      <td>7</td>\n",
              "      <td>c04m122e01_2022.csv</td>\n",
              "      <td>97</td>\n",
              "      <td>c04m122e01_2023.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>c05m028e04_2021.csv</td>\n",
              "      <td>162</td>\n",
              "      <td>c05m028e04_2022.csv</td>\n",
              "      <td>221</td>\n",
              "      <td>c05m028e04_2023.csv</td>\n",
              "      <td>533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>c05m031e04_2021.csv</td>\n",
              "      <td>210</td>\n",
              "      <td>c05m031e04_2022.csv</td>\n",
              "      <td>110</td>\n",
              "      <td>c05m031e04_2023.csv</td>\n",
              "      <td>450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>c05m040e13_2021.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c05m040e13_2022.csv</td>\n",
              "      <td>1311</td>\n",
              "      <td>c05m040e13_2023.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>c05m041e09_2021.csv</td>\n",
              "      <td>123</td>\n",
              "      <td>c05m041e09_2022.csv</td>\n",
              "      <td>7</td>\n",
              "      <td>c05m041e09_2023.csv</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>c05m050e01_2021.csv</td>\n",
              "      <td>254</td>\n",
              "      <td>c05m050e01_2022.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c05m050e01_2023.csv</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>c05m105e08_2021.csv</td>\n",
              "      <td>11</td>\n",
              "      <td>c05m105e08_2022.csv</td>\n",
              "      <td>7</td>\n",
              "      <td>c05m105e08_2023.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>c05m105e09_2021.csv</td>\n",
              "      <td>35</td>\n",
              "      <td>c05m105e09_2022.csv</td>\n",
              "      <td>6</td>\n",
              "      <td>c05m105e09_2023.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>c05m124e01_2021.csv</td>\n",
              "      <td>9</td>\n",
              "      <td>c05m124e01_2022.csv</td>\n",
              "      <td>9</td>\n",
              "      <td>c05m124e01_2023.csv</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>c05m128e02_2021.csv</td>\n",
              "      <td>824</td>\n",
              "      <td>c05m128e02_2022.csv</td>\n",
              "      <td>1050</td>\n",
              "      <td>c05m128e02_2023.csv</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-609cd969-d370-4f6f-9695-e21c1648f460')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-609cd969-d370-4f6f-9695-e21c1648f460 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-609cd969-d370-4f6f-9695-e21c1648f460');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7192c4c1-a144-457e-9eef-64587b240151\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7192c4c1-a144-457e-9eef-64587b240151')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7192c4c1-a144-457e-9eef-64587b240151 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_627486b3-41f7-49cf-8693-b90b3b746f64\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('missing_all')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_627486b3-41f7-49cf-8693-b90b3b746f64 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('missing_all');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Unnamed: 0         file_name_21  missing_values_21         file_name_22  \\\n",
              "0            0  c01m045e01_2021.csv                  6  c01m045e01_2022.csv   \n",
              "1            1  c01m061e01_2021.csv                228  c01m061e01_2022.csv   \n",
              "2            2  c01m080e01_2021.csv                  6  c01m080e01_2022.csv   \n",
              "3            3  c01m083e01_2021.csv                 12  c01m083e01_2022.csv   \n",
              "4            4  c01m127e01_2021.csv                406  c01m127e01_2022.csv   \n",
              "5            5  c01m141e01_2021.csv                241  c01m141e01_2022.csv   \n",
              "6            6  c02m026e02_2021.csv                 17  c02m026e02_2022.csv   \n",
              "7            7  c02m042e02_2021.csv                483  c02m042e02_2022.csv   \n",
              "8            8  c02m042e03_2021.csv               1147  c02m042e03_2022.csv   \n",
              "9            9  c02m051e03_2021.csv                210  c02m051e03_2022.csv   \n",
              "10          10  c02m119e02_2021.csv                694  c02m119e02_2022.csv   \n",
              "11          11  c03m034e01_2021.csv               3152  c03m034e01_2022.csv   \n",
              "12          12  c03m070e01_2021.csv                 73  c03m070e01_2022.csv   \n",
              "13          13  c03m093e04_2021.csv                 20  c03m093e04_2022.csv   \n",
              "14          14  c03m096e01_2021.csv               1457  c03m096e01_2022.csv   \n",
              "15          15  c03m102e01_2021.csv                 61  c03m102e01_2022.csv   \n",
              "16          16  c03m121e01_2021.csv                833  c03m121e01_2022.csv   \n",
              "17          17  c04m122e01_2021.csv                  7  c04m122e01_2022.csv   \n",
              "18          18  c05m028e04_2021.csv                162  c05m028e04_2022.csv   \n",
              "19          19  c05m031e04_2021.csv                210  c05m031e04_2022.csv   \n",
              "20          20  c05m040e13_2021.csv                  6  c05m040e13_2022.csv   \n",
              "21          21  c05m041e09_2021.csv                123  c05m041e09_2022.csv   \n",
              "22          22  c05m050e01_2021.csv                254  c05m050e01_2022.csv   \n",
              "23          23  c05m105e08_2021.csv                 11  c05m105e08_2022.csv   \n",
              "24          24  c05m105e09_2021.csv                 35  c05m105e09_2022.csv   \n",
              "25          25  c05m124e01_2021.csv                  9  c05m124e01_2022.csv   \n",
              "26          26  c05m128e02_2021.csv                824  c05m128e02_2022.csv   \n",
              "\n",
              "    missing_values_22         file_name_23  missing_values_23  \n",
              "0                   6  c01m045e01_2023.csv                  7  \n",
              "1                 875  c01m061e01_2023.csv                  8  \n",
              "2                 246  c01m080e01_2023.csv                 97  \n",
              "3                  23  c01m083e01_2023.csv                129  \n",
              "4                 204  c01m127e01_2023.csv                 11  \n",
              "5                   7  c01m141e01_2023.csv                 10  \n",
              "6                1419  c02m026e02_2023.csv                240  \n",
              "7                 215  c02m042e02_2023.csv                 95  \n",
              "8                6671  c02m042e03_2023.csv               1504  \n",
              "9                   8  c02m051e03_2023.csv                 11  \n",
              "10               2349  c02m119e02_2023.csv                 99  \n",
              "11                  6  c03m034e01_2023.csv                  8  \n",
              "12                750  c03m070e01_2023.csv                 11  \n",
              "13                  6  c03m093e04_2023.csv                 16  \n",
              "14                  8  c03m096e01_2023.csv                  7  \n",
              "15                  7  c03m102e01_2023.csv                  7  \n",
              "16                 43  c03m121e01_2023.csv               1977  \n",
              "17                 97  c04m122e01_2023.csv                  8  \n",
              "18                221  c05m028e04_2023.csv                533  \n",
              "19                110  c05m031e04_2023.csv                450  \n",
              "20               1311  c05m040e13_2023.csv                  8  \n",
              "21                  7  c05m041e09_2023.csv                  7  \n",
              "22                  6  c05m050e01_2023.csv                  7  \n",
              "23                  7  c05m105e08_2023.csv                  8  \n",
              "24                  6  c05m105e09_2023.csv                  8  \n",
              "25                  9  c05m124e01_2023.csv                  7  \n",
              "26               1050  c05m128e02_2023.csv                 18  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "missing_all= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Avamet/missing_values_all_years.csv')\n",
        "missing_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPa34gjSkz_X",
        "outputId": "ef7f9740-1017-4021-ffb3-dd63f03e4390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All missing counts saved to combined_missing_data_counts_23.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def process_file(file_path, file_name):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['is_missing'] = df['temp_value'].isnull()\n",
        "\n",
        "\n",
        "    df['missing_group'] = (df['is_missing'] != df['is_missing'].shift()).cumsum()\n",
        "    missing_data_df = df[df['is_missing']]\n",
        "\n",
        "    missing_counts = missing_data_df.groupby('missing_group')['temp_value'].size().reset_index(name='missing_count')\n",
        "    missing_counts['file_name'] = file_name\n",
        "\n",
        "    return missing_counts\n",
        "\n",
        "# Function to process all files in a directory and save results in one file\n",
        "def process_all_files_in_folder(folder_path, output_file):\n",
        "    file_list = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "    all_missing_counts = []\n",
        "\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        missing_counts = process_file(file_path, file_name)\n",
        "        all_missing_counts.append(missing_counts)\n",
        "\n",
        "    # Concatenate all the missing counts into a single DataFrame\n",
        "    combined_missing_counts = pd.concat(all_missing_counts, ignore_index=True)\n",
        "\n",
        "    # Save the combined missing counts to a single CSV file\n",
        "    combined_missing_counts.to_csv(output_file, index=False)\n",
        "    print(f\"All missing counts saved to {output_file}\")\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Resampled/\"\n",
        "output_file = 'combined_missing_data_counts_23.csv'\n",
        "\n",
        "process_all_files_in_folder(folder_path, output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuEL0SY3TYfN"
      },
      "source": [
        "# Linear Interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi3j3lJ6bIEG"
      },
      "source": [
        "**150 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArZPTRmATXfn",
        "outputId": "3db3b568-bec2-4e6e-cc49-fd0cf21977e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 5.5961 | MAPE: 0.4204 | MAE: 4.6936\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 2.9491 | MAPE: 0.1587 | MAE: 2.2611\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 2.5564 | MAPE: 0.0970 | MAE: 2.1402\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 4.4090 | MAPE: 0.3090 | MAE: 3.4873\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 5.9770 | MAPE: 0.3474 | MAE: 4.8061\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 6.2668 | MAPE: 0.2828 | MAE: 4.8389\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 5.2205 | MAPE: 0.5099 | MAE: 4.5403\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 4.4527 | MAPE: 0.1723 | MAE: 3.5843\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 1.9439 | MAPE: 0.1234 | MAE: 1.6323\n",
            "\n",
            "Linear interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_linear_interpolation_150.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'  # Default year\n",
        "\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        gap_size = 150\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='linear')\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f} | MAE: {mae:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_linear_interpolation_150.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nLinear interpolation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6s2OBAkbMMW"
      },
      "source": [
        "**300 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ9-z6L6bMMW",
        "outputId": "539f66a8-2843-44df-8685-f76fa905bdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 4.8333 | MAPE: 0.3375\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 2.1121 | MAPE: 0.1057\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 3.4019 | MAPE: 0.1342\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 2.8927 | MAPE: 0.2121\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 4.1008 | MAPE: 0.2287\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 5.1312 | MAPE: 0.2195\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 4.1902 | MAPE: 0.3929\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 5.2449 | MAPE: 0.2054\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 2.2472 | MAPE: 0.1085\n",
            "\n",
            "Linear interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_linear_interpolation_300.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 300\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='linear')\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_linear_interpolation_300.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nLinear interpolation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q6Afe-tbMSV"
      },
      "source": [
        "**450 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21K_1oJvbMSW",
        "outputId": "088c75a8-ef6e-48a6-b5bd-29e9cb0062d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 6.7331 | MAPE: 0.5188\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 3.2259 | MAPE: 0.1610\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 4.8845 | MAPE: 0.2062\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 4.6570 | MAPE: 0.3679\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 4.0127 | MAPE: 0.2246\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 5.6198 | MAPE: 0.2444\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 4.8964 | MAPE: 0.4645\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 6.1145 | MAPE: 0.2496\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 2.5844 | MAPE: 0.1372\n",
            "\n",
            "Linear interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_linear_interpolation_450.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 450\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='linear')\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_linear_interpolation_450.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nLinear interpolation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DirYCDAzbMWm"
      },
      "source": [
        "**600 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KUy3lBdbMWn",
        "outputId": "21938e28-d32c-4df9-cb1c-79362b618a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 5.4513 | MAPE: 0.3849\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 3.6705 | MAPE: 0.1834\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 5.3082 | MAPE: 0.2240\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 5.3007 | MAPE: 0.4089\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 6.0832 | MAPE: 0.3675\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 7.0436 | MAPE: 0.3137\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 4.2661 | MAPE: 0.3972\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 7.1581 | MAPE: 0.2996\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 2.9741 | MAPE: 0.1586\n",
            "\n",
            "Linear interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_linear_interpolation_600.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 600\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='linear')\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_linear_interpolation_600.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nLinear interpolation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3nInzJxc2UA"
      },
      "source": [
        "# Spline Interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq1NSjGSc2UA"
      },
      "source": [
        "**150 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UryHo3omc2UB",
        "outputId": "807bd3e2-8a06-48ac-f08c-b7ec18010ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 8.1125 | MAPE: 0.6183\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 3.5427 | MAPE: 0.2014\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 4.5828 | MAPE: 0.1837\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 6.1884 | MAPE: 0.4462\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 10.3698 | MAPE: 0.6265\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 11.3412 | MAPE: 0.5373\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 8.5621 | MAPE: 0.8395\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 8.4695 | MAPE: 0.3397\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 2.7534 | MAPE: 0.1787\n",
            "\n",
            "Spline interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_spline_interpolation_150.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 150\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='spline', order=3)\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_spline_interpolation_150.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "print(f\"\\nSpline interpolation completed for all files. Results saved to {comparison_results_file}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODYUlUkpc2UC"
      },
      "source": [
        "**300 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QotY4KCc2UC",
        "outputId": "795c7737-7488-417b-8a36-dcb791305ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 8.0640 | MAPE: 0.5921\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 3.5937 | MAPE: 0.1880\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 9.7346 | MAPE: 0.4136\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 7.3297 | MAPE: 0.5714\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 5.2852 | MAPE: 0.3031\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 13.9212 | MAPE: 0.6444\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 10.1595 | MAPE: 0.9463\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 10.6673 | MAPE: 0.4538\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 3.4289 | MAPE: 0.1942\n",
            "\n",
            "Spline interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_spline_interpolation_300.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 300\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='spline', order=3)\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df['File Name'] = pd.Categorical(comparison_df['File Name'], categories=[\n",
        "    'c01m045e01_2021', 'c05m124e01_2021', 'c05m105e08_2021',\n",
        "    'c01m045e01_2022', 'c05m124e01_2022', 'c05m105e08_2022',\n",
        "    'c01m045e01_2023', 'c05m124e01_2023', 'c05m105e08_2023'\n",
        "], ordered=True)\n",
        "comparison_df.sort_values(by=['File Name'], inplace=True)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_spline_interpolation_300.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "print(f\"\\nSpline interpolation completed for all files. Results saved to {comparison_results_file}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9H1fHfsc2UC"
      },
      "source": [
        "**450 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgENIDhIc2UC",
        "outputId": "37386c37-d28a-47b1-ab7e-15c08f2e1b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 15.7474 | MAPE: 1.2238\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 6.4812 | MAPE: 0.3469\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 14.1173 | MAPE: 0.6166\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 16.7273 | MAPE: 1.3312\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 19.7677 | MAPE: 1.2083\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 29.6028 | MAPE: 1.3555\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 19.3974 | MAPE: 1.8240\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 23.9803 | MAPE: 1.0511\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 5.4019 | MAPE: 0.2960\n",
            "\n",
            "Spline interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_spline_interpolation_450.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 450\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='spline', order=3)\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df['File Name'] = pd.Categorical(comparison_df['File Name'], categories=[\n",
        "    'c01m045e01_2021', 'c05m124e01_2021', 'c05m105e08_2021',\n",
        "    'c01m045e01_2022', 'c05m124e01_2022', 'c05m105e08_2022',\n",
        "    'c01m045e01_2023', 'c05m124e01_2023', 'c05m105e08_2023'\n",
        "], ordered=True)\n",
        "comparison_df.sort_values(by=['File Name'], inplace=True)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_spline_interpolation_450.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "print(f\"\\nSpline interpolation completed for all files. Results saved to {comparison_results_file}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Wfr_slc2UC"
      },
      "source": [
        "**600 GAP SIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHMmDl0kc2UC",
        "outputId": "7594039e-04e1-4116-d1e5-5a9682085c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed file: c01m045e01_2021.csv | RMSE: 13.6892 | MAPE: 0.9322\n",
            "Processed file: c05m124e01_2021.csv | RMSE: 6.2446 | MAPE: 0.3147\n",
            "Processed file: c05m105e08_2022.csv | RMSE: 6.8165 | MAPE: 0.2907\n",
            "Processed file: c05m105e08_2023.csv | RMSE: 19.6346 | MAPE: 1.5183\n",
            "Processed file: c05m124e01_2023.csv | RMSE: 29.3494 | MAPE: 1.7803\n",
            "Processed file: c01m045e01_2022.csv | RMSE: 39.6371 | MAPE: 1.8087\n",
            "Processed file: c01m045e01_2023.csv | RMSE: 18.1318 | MAPE: 1.6380\n",
            "Processed file: c05m124e01_2022.csv | RMSE: 35.5082 | MAPE: 1.5495\n",
            "Processed file: c05m105e08_2021.csv | RMSE: 4.7657 | MAPE: 0.2767\n",
            "\n",
            "Linear interpolation completed for all files. Results saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results/comparison_spline_interpolation_600.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Results'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "        start_gap = 6700\n",
        "        gap_size = 600\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "        data_filtered_with_nan['temp_value_imp'] = data_filtered_with_nan['temp_value_imp'].interpolate(method='spline', order=3)\n",
        "\n",
        "        original_values = data_filtered.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "        imputed_values = data_filtered_with_nan.loc[start_gap:start_gap + gap_size - 1, 'temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae=mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'Year': year, 'File Name': file_name.split('.')[0], 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df['File Name'] = pd.Categorical(comparison_df['File Name'], categories=[\n",
        "    'c01m045e01_2021', 'c05m124e01_2021', 'c05m105e08_2021',\n",
        "    'c01m045e01_2022', 'c05m124e01_2022', 'c05m105e08_2022',\n",
        "    'c01m045e01_2023', 'c05m124e01_2023', 'c05m105e08_2023'\n",
        "], ordered=True)\n",
        "comparison_df.sort_values(by=['File Name'], inplace=True)\n",
        "comparison_results_file = os.path.join(output_folder_path, 'comparison_spline_interpolation_600.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "print(f\"\\nSpline interpolation completed for all files. Results saved to {comparison_results_file}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blnw307afuzj"
      },
      "source": [
        "# XGBoost Data Imputation - Limited Selected Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gap with 150 Values**"
      ],
      "metadata": {
        "id": "LjU7bdhLdbFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR1J4_Ylkc34"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "import plotly.express as px\n",
        "from plotly.io import write_image\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Plots'\n",
        "# output_folder_path = '/content/'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "\n",
        "        # Introduce a gap of 150 consecutive NaN values\n",
        "        start_gap = 7200\n",
        "        gap_size = 150\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered_with_nan['time_step'] = range(len(data_filtered_with_nan))\n",
        "        data_filtered_with_nan['hour'] = data_filtered_with_nan['timestamp'].dt.hour\n",
        "        data_filtered_with_nan['minute'] = data_filtered_with_nan['timestamp'].dt.minute\n",
        "        data_filtered_with_nan['day_of_week'] = data_filtered_with_nan['timestamp'].dt.dayofweek\n",
        "        data_filtered_with_nan['month'] = data_filtered_with_nan['timestamp'].dt.month\n",
        "\n",
        "        # Separate the data into known and missing parts\n",
        "        known_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].notna()]\n",
        "        missing_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].isna()]\n",
        "\n",
        "        # Define features and target\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value_imp']\n",
        "        X_missing = missing_data[features]\n",
        "\n",
        "        # Train XGBoost regressor\n",
        "        xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "        xgb_model.fit(X_known, y_known)\n",
        "\n",
        "        # Predict missing values\n",
        "        missing_data['temp_value_imp'] = xgb_model.predict(X_missing)\n",
        "\n",
        "        # Combine the imputed data with the known data\n",
        "        imputed_data = data_filtered_with_nan.copy()\n",
        "        imputed_data.loc[missing_data.index, 'temp_value_imp'] = missing_data['temp_value_imp']\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "\n",
        "        # Plot original vs imputed data for visualization using Plotly Express\n",
        "        fig = px.line(\n",
        "            missing_data,\n",
        "            x=missing_data.index,\n",
        "            y='temp_value_imp',\n",
        "            width=1000, height=800,\n",
        "            title=f'Original vs Imputed Data - {file_name}',\n",
        "            labels={'temp_value_imp': 'Temperature', 'index': 'Time'},\n",
        "            color_discrete_sequence=['blue']\n",
        "        )\n",
        "        fig.add_scatter(x=original_values.index, y=original_values.values, mode='lines', name='Original', line=dict(color='blue', dash='solid'))\n",
        "        fig.add_scatter(x=missing_data.index, y=missing_data['temp_value_imp'], mode='lines', name='Imputed', line=dict(color='red', dash='solid'))\n",
        "\n",
        "\n",
        "        # Add the name for imputed data in the legend\n",
        "        fig.update_traces(name='Imputed', selector=dict(mode='lines'))\n",
        "\n",
        "        # Save the plot as a PNG file\n",
        "        plot_file_name = f\"{file_name.split('.')[0]}_{gap_size}.png\"\n",
        "        plot_file_path = os.path.join(output_folder_path, plot_file_name)\n",
        "        fig.write_image(plot_file_path, scale=2)\n",
        "\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "        imputed_values = missing_data['temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae = mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'File Name': file_name, 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        # print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "# Save comparison results to a CSV file\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df[\"Year\"] = comparison_df[\"File Name\"].str.extract(r\"_(\\d{4})\\.csv\")\n",
        "comparison_df[\"Suffix\"] = comparison_df[\"File Name\"].str.extract(r\"e(\\d{2})_\")\n",
        "comparison_df = comparison_df.sort_values(by=[\"Year\", \"Suffix\"])\n",
        "comparison_df = comparison_df.drop(columns=[\"Year\", \"Suffix\"])\n",
        "comparison_results_file = os.path.join(output_folder_path, 'imputation_comparison_results_150.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nImputation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-j8GxRXC2Cl"
      },
      "source": [
        "**Gap with 300 Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwqh1N3GC2Cl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "import plotly.express as px\n",
        "from plotly.io import write_image\n",
        "\n",
        "# Specify folder paths and file patterns\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Plots'\n",
        "# output_folder_path = '/content/'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "# Process all relevant files\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-04-01') & (data['timestamp'] <= f'{year}-06-30')].reset_index(drop=True)\n",
        "\n",
        "\n",
        "        # Introduce a gap of 300 consecutive NaN values in 'temp_value_imp'\n",
        "        start_gap = 3400\n",
        "        gap_size = 300\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered_with_nan['time_step'] = range(len(data_filtered_with_nan))\n",
        "        data_filtered_with_nan['hour'] = data_filtered_with_nan['timestamp'].dt.hour\n",
        "        data_filtered_with_nan['minute'] = data_filtered_with_nan['timestamp'].dt.minute\n",
        "        data_filtered_with_nan['day_of_week'] = data_filtered_with_nan['timestamp'].dt.dayofweek\n",
        "        data_filtered_with_nan['month'] = data_filtered_with_nan['timestamp'].dt.month\n",
        "\n",
        "\n",
        "        # Separate the data into known and missing parts\n",
        "        known_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].notna()]\n",
        "        missing_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].isna()]\n",
        "\n",
        "        # Define features and target\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value_imp']\n",
        "        X_missing = missing_data[features]\n",
        "\n",
        "        # Train XGBoost regressor\n",
        "        xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "        xgb_model.fit(X_known, y_known)\n",
        "\n",
        "        # Predict missing values\n",
        "        missing_data['temp_value_imp'] = xgb_model.predict(X_missing)\n",
        "\n",
        "        # Combine the imputed data with the known data\n",
        "        imputed_data = data_filtered_with_nan.copy()\n",
        "        imputed_data.loc[missing_data.index, 'temp_value_imp'] = missing_data['temp_value_imp']\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "\n",
        "        # Plot original vs imputed data for visualization using Plotly Express\n",
        "        fig = px.line(\n",
        "            missing_data,\n",
        "            x=missing_data.index,\n",
        "            y='temp_value_imp',\n",
        "            width=1000, height=800,\n",
        "            title=f'Original vs Imputed Data - {file_name}',\n",
        "            labels={'temp_value_imp': 'Temperature', 'index': 'Time'},\n",
        "            color_discrete_sequence=['blue']\n",
        "        )\n",
        "        fig.add_scatter(x=original_values.index, y=original_values.values, mode='lines', name='Original', line=dict(color='blue', dash='solid'))\n",
        "        fig.add_scatter(x=missing_data.index, y=missing_data['temp_value_imp'], mode='lines', name='Imputed', line=dict(color='red', dash='solid'))\n",
        "\n",
        "\n",
        "        # Add the name for imputed data in the legend\n",
        "        fig.update_traces(name='Imputed', selector=dict(mode='lines'))\n",
        "\n",
        "        # Save the plot as a PNG file\n",
        "        plot_file_name = f\"{file_name.split('.')[0]}_{gap_size}.png\"\n",
        "        plot_file_path = os.path.join(output_folder_path, plot_file_name)\n",
        "        fig.write_image(plot_file_path, scale=2)\n",
        "\n",
        "\n",
        "        # Evaluate the performance (RMSE, MAPE)\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "        imputed_values = missing_data['temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae = mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'File Name': file_name, 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        # print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f} | MAE: {mae:.4f}\")\n",
        "\n",
        "# Save comparison results to a CSV file\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df[\"Year\"] = comparison_df[\"File Name\"].str.extract(r\"_(\\d{4})\\.csv\")\n",
        "comparison_df[\"Suffix\"] = comparison_df[\"File Name\"].str.extract(r\"e(\\d{2})_\")\n",
        "comparison_df = comparison_df.sort_values(by=[\"Year\", \"Suffix\"])\n",
        "comparison_df = comparison_df.drop(columns=[\"Year\", \"Suffix\"])\n",
        "comparison_results_file = os.path.join(output_folder_path, 'imputation_comparison_results_300.csv')\n",
        "comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nImputation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNA0eSSnC2PV"
      },
      "source": [
        "**Gap with 450 Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYgf5PT7C2PV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error\n",
        "import plotly.express as px\n",
        "from plotly.io import write_image\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Plots'\n",
        "# output_folder_path = '/content/'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-06-01') & (data['timestamp'] <= f'{year}-08-30')].reset_index(drop=True)\n",
        "\n",
        "        # Introduce a gap of 150 consecutive NaN values in 'temp_value_imp'\n",
        "        start_gap = 6700\n",
        "        gap_size = 450\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered_with_nan['time_step'] = range(len(data_filtered_with_nan))\n",
        "        data_filtered_with_nan['hour'] = data_filtered_with_nan['timestamp'].dt.hour\n",
        "        data_filtered_with_nan['minute'] = data_filtered_with_nan['timestamp'].dt.minute\n",
        "        data_filtered_with_nan['day_of_week'] = data_filtered_with_nan['timestamp'].dt.dayofweek\n",
        "        data_filtered_with_nan['month'] = data_filtered_with_nan['timestamp'].dt.month\n",
        "\n",
        "        # Separate the data into known and missing parts\n",
        "        known_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].notna()]\n",
        "        missing_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].isna()]\n",
        "\n",
        "        # Define features and target\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value_imp']\n",
        "        X_missing = missing_data[features]\n",
        "\n",
        "        # Train XGBoost regressor\n",
        "        xgb_model = XGBRegressor(n_estimators=150, learning_rate=0.0575, max_depth=3, random_state=42)\n",
        "        xgb_model.fit(X_known, y_known)\n",
        "\n",
        "\n",
        "        missing_data['temp_value_imp'] = xgb_model.predict(X_missing)\n",
        "\n",
        "        # Combine the imputed data with the known data\n",
        "        imputed_data = data_filtered_with_nan.copy()\n",
        "        imputed_data.loc[missing_data.index, 'temp_value_imp'] = missing_data['temp_value_imp']\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "\n",
        "        # Plot original vs imputed data for visualization using Plotly Express\n",
        "        fig = px.line(\n",
        "            missing_data,\n",
        "            x=missing_data.index,\n",
        "            y='temp_value_imp',\n",
        "            width=1000, height=800,\n",
        "            title=f'Original vs Imputed Data - {file_name}',\n",
        "            labels={'temp_value_imp': 'Temperature', 'index': 'Time'},\n",
        "            color_discrete_sequence=['blue']\n",
        "        )\n",
        "        fig.add_scatter(x=original_values.index, y=original_values.values, mode='lines', name='Original', line=dict(color='blue', dash='solid'))\n",
        "        fig.add_scatter(x=missing_data.index, y=missing_data['temp_value_imp'], mode='lines', name='Imputed', line=dict(color='red', dash='solid'))\n",
        "        fig.update_traces(name='Imputed', selector=dict(mode='lines'))\n",
        "\n",
        "        plot_file_name = f\"{file_name.split('.')[0]}_{gap_size}.png\"\n",
        "        plot_file_path = os.path.join(output_folder_path, plot_file_name)\n",
        "        # fig.write_image(plot_file_path, scale=2)\n",
        "\n",
        "\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "        imputed_values = missing_data['temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae = mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'File Name': file_name, 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "# Save comparison results to a CSV file\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df[\"Year\"] = comparison_df[\"File Name\"].str.extract(r\"_(\\d{4})\\.csv\")\n",
        "comparison_df[\"Suffix\"] = comparison_df[\"File Name\"].str.extract(r\"e(\\d{2})_\")\n",
        "comparison_df = comparison_df.sort_values(by=[\"Year\", \"Suffix\"])\n",
        "comparison_df = comparison_df.drop(columns=[\"Year\", \"Suffix\"])\n",
        "# comparison_results_file = os.path.join(output_folder_path, 'imputation_comparison_results_450.csv')\n",
        "# comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nImputation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7j46gw7C2ZU"
      },
      "source": [
        "**Gap with 600 Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VjTpqgC2ZV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error,mean_absolute_error\n",
        "import plotly.express as px\n",
        "from plotly.io import write_image\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Plots'\n",
        "# output_folder_path = '/content/'\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-06-01') & (data['timestamp'] <= f'{year}-08-30')].reset_index(drop=True)\n",
        "\n",
        "        # Introduce a gap of 600 consecutive NaN values in 'temp_value_imp'\n",
        "        start_gap = 6700\n",
        "        gap_size = 300\n",
        "        data_filtered_with_nan = data_filtered.copy()\n",
        "        data_filtered_with_nan.iloc[start_gap:start_gap + gap_size, data_filtered.columns.get_loc('temp_value_imp')] = np.nan\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered_with_nan['time_step'] = range(len(data_filtered_with_nan))\n",
        "        data_filtered_with_nan['hour'] = data_filtered_with_nan['timestamp'].dt.hour\n",
        "        data_filtered_with_nan['minute'] = data_filtered_with_nan['timestamp'].dt.minute\n",
        "        data_filtered_with_nan['day_of_week'] = data_filtered_with_nan['timestamp'].dt.dayofweek\n",
        "        data_filtered_with_nan['month'] = data_filtered_with_nan['timestamp'].dt.month\n",
        "\n",
        "        # Separate the data into known and missing parts\n",
        "        known_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].notna()]\n",
        "        missing_data = data_filtered_with_nan[data_filtered_with_nan['temp_value_imp'].isna()]\n",
        "\n",
        "        # Define features and target\n",
        "        features = ['time_step','hour', 'minute', 'day_of_week', 'month']\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value_imp']\n",
        "        X_missing = missing_data[features]\n",
        "\n",
        "        # Train XGBoost regressor\n",
        "        #{'subsample': 0.6, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
        "        xgb_model = XGBRegressor(subsample=0.6, n_estimators=150, max_depth=3, learning_rate=0.0575, colsample_bytree= 0.6, random_state=42)\n",
        "        # xgb_model = XGBRegressor(n_estimators=150, learning_rate=0.0575, max_depth=3, random_state=42)\n",
        "        xgb_model.fit(X_known, y_known)\n",
        "\n",
        "        # feature_importances = pd.DataFrame({\n",
        "        #                     'Feature': features,\n",
        "        #                     'Importance': xgb_model.feature_importances_\n",
        "        #                 }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "        # print(f\"Feature Importance for {file_name}:\\n\", feature_importances)\n",
        "\n",
        "        # Predict missing values\n",
        "        missing_data['temp_value_imp'] = xgb_model.predict(X_missing)\n",
        "\n",
        "\n",
        "        imputed_data = data_filtered_with_nan.copy()\n",
        "        imputed_data.loc[missing_data.index, 'temp_value_imp'] = missing_data['temp_value_imp']\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "\n",
        "        # Plot original vs imputed data for visualization using Plotly Express\n",
        "        fig = px.line(\n",
        "            missing_data,\n",
        "            x=missing_data.index,\n",
        "            y='temp_value_imp',\n",
        "            width=1000, height=800,\n",
        "            title=f'Original vs Imputed Data - {file_name}',\n",
        "            labels={'temp_value_imp': 'Temperature', 'index': 'Time'},\n",
        "            color_discrete_sequence=['blue']\n",
        "        )\n",
        "        fig.add_scatter(x=original_values.index, y=original_values.values, mode='lines', name='Original', line=dict(color='blue', dash='solid'))\n",
        "        fig.add_scatter(x=missing_data.index, y=missing_data['temp_value_imp'], mode='lines', name='Imputed', line=dict(color='red', dash='solid'))\n",
        "        fig.update_traces(name='Imputed', selector=dict(mode='lines'))\n",
        "\n",
        "        plot_file_name = f\"{file_name.split('.')[0]}_{gap_size}.png\"\n",
        "        plot_file_path = os.path.join(output_folder_path, plot_file_name)\n",
        "        # fig.write_image(plot_file_path, scale=2)\n",
        "        # fig.show()\n",
        "\n",
        "        original_values = data_filtered.loc[missing_data.index, 'temp_value_imp']\n",
        "        imputed_values = missing_data['temp_value_imp']\n",
        "\n",
        "        rmse = root_mean_squared_error(original_values, imputed_values)\n",
        "        mape = mean_absolute_percentage_error(original_values, imputed_values)\n",
        "        mae = mean_absolute_error(original_values, imputed_values)\n",
        "        comparison_results.append({'File Name': file_name, 'RMSE': rmse, 'MAPE': mape, 'MAE': mae})\n",
        "        # print(f\"Processed file: {file_name} | RMSE: {rmse:.4f} | MAPE: {mape:.4f}\")\n",
        "\n",
        "# Save comparison results to a CSV file\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "comparison_df[\"Year\"] = comparison_df[\"File Name\"].str.extract(r\"_(\\d{4})\\.csv\")\n",
        "comparison_df[\"Suffix\"] = comparison_df[\"File Name\"].str.extract(r\"e(\\d{2})_\")\n",
        "comparison_df = comparison_df.sort_values(by=[\"Year\", \"Suffix\"])\n",
        "comparison_df = comparison_df.drop(columns=[\"Year\", \"Suffix\"])\n",
        "# comparison_results_file = os.path.join(output_folder_path, 'imputation_comparison_results_{gap_size}.csv')\n",
        "# comparison_df.to_csv(comparison_results_file, index=False)\n",
        "\n",
        "print(f\"\\nImputation completed for all files. Results saved to {comparison_results_file}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "k_TD_TZiOd6X",
        "outputId": "d5a28e4b-a4e6-4a0a-e72a-e33f6ea0b9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             File Name      RMSE      MAPE       MAE\n",
              "0  c01m045e01_2021.csv  1.786940  0.065367  1.507172\n",
              "1  c05m124e01_2021.csv  1.346937  0.044595  1.082356\n",
              "8  c05m105e08_2021.csv  1.318189  0.044253  1.048672\n",
              "5  c01m045e01_2022.csv  1.558206  0.049217  1.312973\n",
              "7  c05m124e01_2022.csv  1.922354  0.058601  1.603477\n",
              "2  c05m105e08_2022.csv  1.139016  0.036404  0.961973\n",
              "4  c05m124e01_2023.csv  2.150134  0.058400  1.675614\n",
              "6  c01m045e01_2023.csv  6.630257  0.196111  5.762467\n",
              "3  c05m105e08_2023.csv  5.597830  0.154308  4.599021"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1eaef5b6-9be4-48c9-911c-6d40c80a760f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c01m045e01_2021.csv</td>\n",
              "      <td>1.786940</td>\n",
              "      <td>0.065367</td>\n",
              "      <td>1.507172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c05m124e01_2021.csv</td>\n",
              "      <td>1.346937</td>\n",
              "      <td>0.044595</td>\n",
              "      <td>1.082356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>c05m105e08_2021.csv</td>\n",
              "      <td>1.318189</td>\n",
              "      <td>0.044253</td>\n",
              "      <td>1.048672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c01m045e01_2022.csv</td>\n",
              "      <td>1.558206</td>\n",
              "      <td>0.049217</td>\n",
              "      <td>1.312973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>c05m124e01_2022.csv</td>\n",
              "      <td>1.922354</td>\n",
              "      <td>0.058601</td>\n",
              "      <td>1.603477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c05m105e08_2022.csv</td>\n",
              "      <td>1.139016</td>\n",
              "      <td>0.036404</td>\n",
              "      <td>0.961973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c05m124e01_2023.csv</td>\n",
              "      <td>2.150134</td>\n",
              "      <td>0.058400</td>\n",
              "      <td>1.675614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c01m045e01_2023.csv</td>\n",
              "      <td>6.630257</td>\n",
              "      <td>0.196111</td>\n",
              "      <td>5.762467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c05m105e08_2023.csv</td>\n",
              "      <td>5.597830</td>\n",
              "      <td>0.154308</td>\n",
              "      <td>4.599021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1eaef5b6-9be4-48c9-911c-6d40c80a760f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1eaef5b6-9be4-48c9-911c-6d40c80a760f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1eaef5b6-9be4-48c9-911c-6d40c80a760f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b32eb415-cebf-4e90-9556-e11329098963\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b32eb415-cebf-4e90-9556-e11329098963')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b32eb415-cebf-4e90-9556-e11329098963 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_58a67b6f-319e-4a57-a072-9bfa26169c27\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_58a67b6f-319e-4a57-a072-9bfa26169c27 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"File Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"c01m045e01_2023.csv\",\n          \"c05m124e01_2021.csv\",\n          \"c05m105e08_2022.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.030558555659506,\n        \"min\": 1.1390160936222686,\n        \"max\": 6.63025699906383,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          6.63025699906383,\n          1.3469370989529599,\n          1.1390160936222686\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAPE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05646187515893042,\n        \"min\": 0.03640419525562582,\n        \"max\": 0.19611125394749115,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.19611125394749115,\n          0.04459504942228065,\n          0.03640419525562582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7480266131288595,\n        \"min\": 0.9619727121988934,\n        \"max\": 5.762467114766439,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.762467114766439,\n          1.0823560282389322,\n          0.9619727121988934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(\n",
        "    missing_data,\n",
        "    x=missing_data.index,\n",
        "    y='temp_value_imp',\n",
        "    width=1000, height=800,\n",
        "    title=f'Original vs Imputed Data - {file_name}',\n",
        "    labels={'temp_value_imp': 'Temperature', 'index': 'Time'},\n",
        "    color_discrete_sequence=['blue']\n",
        ")\n",
        "\n",
        "# Add a trace for the original data with a custom legend name\n",
        "fig.add_scatter(x=original_values.index, y=original_values.values, mode='lines', name='Original', line=dict(color='blue', dash='solid'))\n",
        "\n",
        "# Add the name for imputed data in the legend (if it isn't appearing yet)\n",
        "fig.add_scatter(x=missing_data.index, y=missing_data['temp_value_imp'], mode='lines', name='Imputed', line=dict(color='red', dash='solid'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "KMJH9XmA41OJ",
        "outputId": "f836629f-449c-4603-c060-d81558ca6630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c6de047c-859b-46d2-bbe9-fe88fcfdc6d7\" class=\"plotly-graph-div\" style=\"height:800px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c6de047c-859b-46d2-bbe9-fe88fcfdc6d7\")) {                    Plotly.newPlot(                        \"c6de047c-859b-46d2-bbe9-fe88fcfdc6d7\",                        [{\"hovertemplate\":\"Time=%{x}\\u003cbr\\u003eTemperature=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"blue\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[6700,6701,6702,6703,6704,6705,6706,6707,6708,6709,6710,6711,6712,6713,6714,6715,6716,6717,6718,6719,6720,6721,6722,6723,6724,6725,6726,6727,6728,6729,6730,6731,6732,6733,6734,6735,6736,6737,6738,6739,6740,6741,6742,6743,6744,6745,6746,6747,6748,6749,6750,6751,6752,6753,6754,6755,6756,6757,6758,6759,6760,6761,6762,6763,6764,6765,6766,6767,6768,6769,6770,6771,6772,6773,6774,6775,6776,6777,6778,6779,6780,6781,6782,6783,6784,6785,6786,6787,6788,6789,6790,6791,6792,6793,6794,6795,6796,6797,6798,6799,6800,6801,6802,6803,6804,6805,6806,6807,6808,6809,6810,6811,6812,6813,6814,6815,6816,6817,6818,6819,6820,6821,6822,6823,6824,6825,6826,6827,6828,6829,6830,6831,6832,6833,6834,6835,6836,6837,6838,6839,6840,6841,6842,6843,6844,6845,6846,6847,6848,6849,6850,6851,6852,6853,6854,6855,6856,6857,6858,6859,6860,6861,6862,6863,6864,6865,6866,6867,6868,6869,6870,6871,6872,6873,6874,6875,6876,6877,6878,6879,6880,6881,6882,6883,6884,6885,6886,6887,6888,6889,6890,6891,6892,6893,6894,6895,6896,6897,6898,6899,6900,6901,6902,6903,6904,6905,6906,6907,6908,6909,6910,6911,6912,6913,6914,6915,6916,6917,6918,6919,6920,6921,6922,6923,6924,6925,6926,6927,6928,6929,6930,6931,6932,6933,6934,6935,6936,6937,6938,6939,6940,6941,6942,6943,6944,6945,6946,6947,6948,6949,6950,6951,6952,6953,6954,6955,6956,6957,6958,6959,6960,6961,6962,6963,6964,6965,6966,6967,6968,6969,6970,6971,6972,6973,6974,6975,6976,6977,6978,6979,6980,6981,6982,6983,6984,6985,6986,6987,6988,6989,6990,6991,6992,6993,6994,6995,6996,6997,6998,6999],\"xaxis\":\"x\",\"y\":[25.843513,25.843513,26.168673,26.168673,26.168673,26.168673,26.179108,26.179108,26.212942,26.212942,26.212942,26.212942,26.223377,26.223377,26.212942,26.212942,26.212942,26.212942,26.223377,26.223377,26.212942,26.212942,26.212942,26.212942,26.223377,26.223377,26.160769,26.160769,26.160769,26.160769,26.171204,26.171204,25.72523,25.72523,25.710934,25.710934,25.681974,25.681974,25.174953,25.174953,25.160658,25.160658,25.113663,25.095434,24.121737,24.121737,24.10744,24.10744,24.060446,24.042217,22.929483,22.929483,22.915188,22.915188,22.868193,22.849964,22.46694,22.46694,22.452644,22.452644,22.40565,22.38742,22.412355,22.412355,22.39806,22.39806,22.351065,22.332836,22.297338,22.297338,22.297338,22.273966,22.29768,22.285286,22.252308,22.252308,22.252308,22.239239,22.262953,22.250559,22.083498,22.083498,22.092485,22.092485,22.1162,22.11727,21.872826,21.872826,21.881813,21.881813,21.905527,21.906597,21.733467,21.733467,21.742455,21.742455,21.766169,21.767239,21.689648,21.689648,21.698635,21.698635,21.72235,21.72342,21.689648,21.689648,21.698635,21.698635,21.72235,21.72342,21.731394,21.731394,21.740381,21.740381,21.764095,21.795944,22.595846,22.595846,22.604834,22.604834,22.628548,22.660397,23.268238,23.268238,23.277225,23.277225,23.30094,23.332788,23.7617,23.7617,23.770687,23.770687,23.794401,23.82625,24.531866,24.531866,24.540854,24.540854,24.564568,24.596416,25.32143,25.32143,25.32143,25.32143,25.331865,25.331865,25.657024,25.657024,25.657024,25.657024,25.66746,25.66746,25.701294,25.701294,25.701294,25.701294,25.71173,25.71173,25.701294,25.701294,25.701294,25.701294,25.71173,25.71173,25.701294,25.701294,25.701294,25.701294,25.71173,25.71173,25.64912,25.64912,25.64912,25.64912,25.659555,25.659555,25.213581,25.213581,25.199286,25.199286,25.170326,25.170326,24.663305,24.663305,24.64901,24.64901,24.602015,24.583786,23.610088,23.610088,23.595793,23.595793,23.548798,23.53057,22.417835,22.417835,22.40354,22.40354,22.356544,22.338316,21.99431,21.99431,21.980015,21.980015,21.93302,21.914791,21.939726,21.939726,21.92543,21.92543,21.878435,21.860207,21.512564,21.499615,21.503561,21.480188,21.49078,21.478386,21.467533,21.454584,21.45853,21.445461,21.456053,21.443659,21.242764,21.229815,21.242748,21.242748,21.25334,21.25441,20.948547,20.935598,20.948532,20.948532,20.959124,20.960194,20.822676,20.809727,20.82266,20.82266,20.833252,20.834322,20.796692,20.783743,20.796677,20.796677,20.807268,20.808338,20.796692,20.783743,20.796677,20.796677,20.807268,20.808338,20.838438,20.825489,20.838423,20.838423,20.849014,20.880863,21.655977,21.643028,21.655962,21.655962,21.666553,21.698402,22.408558,22.395609,22.408543,22.408543,22.419134,22.450983,23.2683,23.25535,23.268284,23.268284,23.278875,23.310724,24.288475,24.275526,24.276268,24.276268,24.28686,24.318708,25.041037,25.028088,25.019842,25.019842,25.017155,25.017155,25.406557,25.393608,25.385363,25.385363,25.382675,25.382675,25.450827,25.437878,25.429632,25.429632],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"Original\",\"x\":[6700,6701,6702,6703,6704,6705,6706,6707,6708,6709,6710,6711,6712,6713,6714,6715,6716,6717,6718,6719,6720,6721,6722,6723,6724,6725,6726,6727,6728,6729,6730,6731,6732,6733,6734,6735,6736,6737,6738,6739,6740,6741,6742,6743,6744,6745,6746,6747,6748,6749,6750,6751,6752,6753,6754,6755,6756,6757,6758,6759,6760,6761,6762,6763,6764,6765,6766,6767,6768,6769,6770,6771,6772,6773,6774,6775,6776,6777,6778,6779,6780,6781,6782,6783,6784,6785,6786,6787,6788,6789,6790,6791,6792,6793,6794,6795,6796,6797,6798,6799,6800,6801,6802,6803,6804,6805,6806,6807,6808,6809,6810,6811,6812,6813,6814,6815,6816,6817,6818,6819,6820,6821,6822,6823,6824,6825,6826,6827,6828,6829,6830,6831,6832,6833,6834,6835,6836,6837,6838,6839,6840,6841,6842,6843,6844,6845,6846,6847,6848,6849,6850,6851,6852,6853,6854,6855,6856,6857,6858,6859,6860,6861,6862,6863,6864,6865,6866,6867,6868,6869,6870,6871,6872,6873,6874,6875,6876,6877,6878,6879,6880,6881,6882,6883,6884,6885,6886,6887,6888,6889,6890,6891,6892,6893,6894,6895,6896,6897,6898,6899,6900,6901,6902,6903,6904,6905,6906,6907,6908,6909,6910,6911,6912,6913,6914,6915,6916,6917,6918,6919,6920,6921,6922,6923,6924,6925,6926,6927,6928,6929,6930,6931,6932,6933,6934,6935,6936,6937,6938,6939,6940,6941,6942,6943,6944,6945,6946,6947,6948,6949,6950,6951,6952,6953,6954,6955,6956,6957,6958,6959,6960,6961,6962,6963,6964,6965,6966,6967,6968,6969,6970,6971,6972,6973,6974,6975,6976,6977,6978,6979,6980,6981,6982,6983,6984,6985,6986,6987,6988,6989,6990,6991,6992,6993,6994,6995,6996,6997,6998,6999],\"y\":[25.2,25.0,25.1,25.1,24.5,23.9,24.2,23.8,23.8,24.3,24.6,25.2,25.6,25.2,25.4,25.4,25.7,25.7,25.9,25.9,25.8,25.2,25.4,25.8,25.8,26.3,26.5,26.7,26.3,26.1,26.3,25.9,26.2,25.8,26.3,25.7,25.6,25.4,25.1,24.8,24.8,24.4,24.3,24.3,24.6,24.5,24.8,24.2,23.6,23.2,22.8,22.5,21.9,21.6,21.5,21.3,21.1,20.7,20.6,20.4,20.6,20.9,21.1,21.1,21.1,21.3,21.6,21.8,21.9,22.1,22.1,22.2,22.2,22.2,22.3,22.2,22.4,22.4,22.3,22.2,21.5,20.6,19.7,19.4,20.2,20.8,20.7,20.1,20.1,19.7,19.3,19.7,19.8,20.2,19.8,20.3,20.2,19.9,20.2,20.4,20.4,21.2,21.7,21.3,21.3,20.8,20.5,20.6,20.4,20.5,20.2,20.7,21.5,21.7,21.8,21.6,21.7,22.4,22.8,23.6,23.7,23.8,24.1,23.9,24.2,23.7,23.4,23.6,23.8,23.8,24.3,24.3,24.7,24.7,24.7,25.3,25.4,25.4,25.8,25.5,25.5,25.3,25.1,24.9,25.7,25.2,25.3,25.9,25.8,26.1,26.2,26.9,26.7,26.6,26.7,26.9,27.1,27.4,27.5,27.3,27.2,27.1,26.2,26.1,26.4,26.3,26.7,27.1,27.4,27.1,27.2,26.7,26.5,26.2,26.7,26.9,26.7,26.8,26.2,26.3,25.7,25.2,25.1,24.9,25.1,25.2,24.9,25.4,25.4,24.8,24.5,25.0,24.4,24.2,24.1,22.9,22.6,21.8,21.7,21.8,22.0,21.8,21.8,22.1,22.3,22.6,22.3,22.2,21.9,21.5,21.3,20.9,20.8,20.8,21.2,21.1,21.1,20.9,20.9,20.6,20.7,20.6,20.8,20.8,20.7,20.6,20.6,20.6,20.6,20.9,20.7,21.1,21.6,21.5,21.9,21.9,21.6,21.8,21.8,21.7,21.8,21.9,21.8,21.8,21.9,21.8,21.7,21.7,21.7,21.8,21.7,21.8,22.2,21.8,21.9,22.1,22.4,22.4,22.6,24.0,24.4,24.9,24.9,24.4,25.5,24.6,24.9,25.3,25.6,25.9,25.3,25.6,25.3,25.4,25.4,25.8,25.7,25.8,25.6,25.5,26.2,25.9,25.8,26.3,26.5,26.3,26.3,26.2,27.2,27.3,27.3,27.5,28.2,27.9,28.4,27.8,28.1,28.1,27.8,27.9],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"dash\":\"solid\"},\"mode\":\"lines\",\"name\":\"Imputed\",\"x\":[6700,6701,6702,6703,6704,6705,6706,6707,6708,6709,6710,6711,6712,6713,6714,6715,6716,6717,6718,6719,6720,6721,6722,6723,6724,6725,6726,6727,6728,6729,6730,6731,6732,6733,6734,6735,6736,6737,6738,6739,6740,6741,6742,6743,6744,6745,6746,6747,6748,6749,6750,6751,6752,6753,6754,6755,6756,6757,6758,6759,6760,6761,6762,6763,6764,6765,6766,6767,6768,6769,6770,6771,6772,6773,6774,6775,6776,6777,6778,6779,6780,6781,6782,6783,6784,6785,6786,6787,6788,6789,6790,6791,6792,6793,6794,6795,6796,6797,6798,6799,6800,6801,6802,6803,6804,6805,6806,6807,6808,6809,6810,6811,6812,6813,6814,6815,6816,6817,6818,6819,6820,6821,6822,6823,6824,6825,6826,6827,6828,6829,6830,6831,6832,6833,6834,6835,6836,6837,6838,6839,6840,6841,6842,6843,6844,6845,6846,6847,6848,6849,6850,6851,6852,6853,6854,6855,6856,6857,6858,6859,6860,6861,6862,6863,6864,6865,6866,6867,6868,6869,6870,6871,6872,6873,6874,6875,6876,6877,6878,6879,6880,6881,6882,6883,6884,6885,6886,6887,6888,6889,6890,6891,6892,6893,6894,6895,6896,6897,6898,6899,6900,6901,6902,6903,6904,6905,6906,6907,6908,6909,6910,6911,6912,6913,6914,6915,6916,6917,6918,6919,6920,6921,6922,6923,6924,6925,6926,6927,6928,6929,6930,6931,6932,6933,6934,6935,6936,6937,6938,6939,6940,6941,6942,6943,6944,6945,6946,6947,6948,6949,6950,6951,6952,6953,6954,6955,6956,6957,6958,6959,6960,6961,6962,6963,6964,6965,6966,6967,6968,6969,6970,6971,6972,6973,6974,6975,6976,6977,6978,6979,6980,6981,6982,6983,6984,6985,6986,6987,6988,6989,6990,6991,6992,6993,6994,6995,6996,6997,6998,6999],\"y\":[25.843513,25.843513,26.168673,26.168673,26.168673,26.168673,26.179108,26.179108,26.212942,26.212942,26.212942,26.212942,26.223377,26.223377,26.212942,26.212942,26.212942,26.212942,26.223377,26.223377,26.212942,26.212942,26.212942,26.212942,26.223377,26.223377,26.160769,26.160769,26.160769,26.160769,26.171204,26.171204,25.72523,25.72523,25.710934,25.710934,25.681974,25.681974,25.174953,25.174953,25.160658,25.160658,25.113663,25.095434,24.121737,24.121737,24.10744,24.10744,24.060446,24.042217,22.929483,22.929483,22.915188,22.915188,22.868193,22.849964,22.46694,22.46694,22.452644,22.452644,22.40565,22.38742,22.412355,22.412355,22.39806,22.39806,22.351065,22.332836,22.297338,22.297338,22.297338,22.273966,22.29768,22.285286,22.252308,22.252308,22.252308,22.239239,22.262953,22.250559,22.083498,22.083498,22.092485,22.092485,22.1162,22.11727,21.872826,21.872826,21.881813,21.881813,21.905527,21.906597,21.733467,21.733467,21.742455,21.742455,21.766169,21.767239,21.689648,21.689648,21.698635,21.698635,21.72235,21.72342,21.689648,21.689648,21.698635,21.698635,21.72235,21.72342,21.731394,21.731394,21.740381,21.740381,21.764095,21.795944,22.595846,22.595846,22.604834,22.604834,22.628548,22.660397,23.268238,23.268238,23.277225,23.277225,23.30094,23.332788,23.7617,23.7617,23.770687,23.770687,23.794401,23.82625,24.531866,24.531866,24.540854,24.540854,24.564568,24.596416,25.32143,25.32143,25.32143,25.32143,25.331865,25.331865,25.657024,25.657024,25.657024,25.657024,25.66746,25.66746,25.701294,25.701294,25.701294,25.701294,25.71173,25.71173,25.701294,25.701294,25.701294,25.701294,25.71173,25.71173,25.701294,25.701294,25.701294,25.701294,25.71173,25.71173,25.64912,25.64912,25.64912,25.64912,25.659555,25.659555,25.213581,25.213581,25.199286,25.199286,25.170326,25.170326,24.663305,24.663305,24.64901,24.64901,24.602015,24.583786,23.610088,23.610088,23.595793,23.595793,23.548798,23.53057,22.417835,22.417835,22.40354,22.40354,22.356544,22.338316,21.99431,21.99431,21.980015,21.980015,21.93302,21.914791,21.939726,21.939726,21.92543,21.92543,21.878435,21.860207,21.512564,21.499615,21.503561,21.480188,21.49078,21.478386,21.467533,21.454584,21.45853,21.445461,21.456053,21.443659,21.242764,21.229815,21.242748,21.242748,21.25334,21.25441,20.948547,20.935598,20.948532,20.948532,20.959124,20.960194,20.822676,20.809727,20.82266,20.82266,20.833252,20.834322,20.796692,20.783743,20.796677,20.796677,20.807268,20.808338,20.796692,20.783743,20.796677,20.796677,20.807268,20.808338,20.838438,20.825489,20.838423,20.838423,20.849014,20.880863,21.655977,21.643028,21.655962,21.655962,21.666553,21.698402,22.408558,22.395609,22.408543,22.408543,22.419134,22.450983,23.2683,23.25535,23.268284,23.268284,23.278875,23.310724,24.288475,24.275526,24.276268,24.276268,24.28686,24.318708,25.041037,25.028088,25.019842,25.019842,25.017155,25.017155,25.406557,25.393608,25.385363,25.385363,25.382675,25.382675,25.450827,25.437878,25.429632,25.429632],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Temperature\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Original vs Imputed Data - xgboost_tuning_results_all_data.csv\"},\"height\":800,\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c6de047c-859b-46d2-bbe9-fe88fcfdc6d7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Search - Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9syT2QGr7IaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning - Limited Selected Dataset"
      ],
      "metadata": {
        "id": "76Wdc0Ddbhc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/Data Imputation_KV/Imputed Data/\"\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': np.linspace(0.01, 0.2, 5),\n",
        "    'subsample': np.linspace(0.6, 1.0, 5),\n",
        "    'colsample_bytree': np.linspace(0.6, 1.0, 5)\n",
        "}\n",
        "\n",
        "results_dict = {}\n",
        "file_patterns = ['c01m045e01', 'c05m124e01', 'c05m105e08']\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "comparison_results = []\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        print(f\"\\nProcessing file: {file_name}\")\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'  # Default year\n",
        "\n",
        "        # Read the file\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value_imp']]\n",
        "\n",
        "\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-01-01') & (data['timestamp'] <= f'{year}-12-30')].reset_index(drop=True)\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered['time_step'] = range(len(data_filtered))\n",
        "        data_filtered['hour'] = data_filtered['timestamp'].dt.hour\n",
        "        data_filtered['minute'] = data_filtered['timestamp'].dt.minute\n",
        "        data_filtered['day_of_week'] = data_filtered['timestamp'].dt.dayofweek\n",
        "        data_filtered['month'] = data_filtered['timestamp'].dt.month\n",
        "\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X = data_filtered[features]\n",
        "        y = data_filtered['temp_value_imp']\n",
        "\n",
        "        X = X.loc[y.notna()]\n",
        "        y = y.loc[y.notna()]\n",
        "        xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "        # Perform RandomizedSearchCV\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=xgb_model,\n",
        "            param_distributions=param_dist,\n",
        "            scoring='neg_root_mean_squared_error',\n",
        "            n_iter=50,\n",
        "            cv=5,\n",
        "            verbose=1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        random_search.fit(X, y)\n",
        "\n",
        "        # Save Best Parameters and RMSE for this file\n",
        "        best_params = random_search.best_params_\n",
        "        best_rmse = np.sqrt(-random_search.best_score_)\n",
        "\n",
        "        results_dict[file_name] = {\n",
        "            \"Best Parameters\": best_params,\n",
        "            \"Best RMSE\": best_rmse\n",
        "        }\n",
        "\n",
        "        print(f\"Best RMSE for {file_name}: {best_rmse}\")\n",
        "        print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
        "results_output_path = os.path.join(folder_path, \"xgboost_tuning_results_all_data.csv\")\n",
        "results_df.to_csv(results_output_path)\n",
        "\n",
        "print(\"\\n Hyperparameter tuning completed for all files!\")\n",
        "print(f\"Results saved to: {results_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_1qfcQczdXW",
        "outputId": "f0652064-ba73-4566-c17f-99723508bc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: c01m045e01_2021.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m045e01_2021.csv: 2.237122792687971\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c05m124e01_2021.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m124e01_2021.csv: 2.1015662056553825\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m105e08_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e08_2022.csv: 2.166334558007655\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c05m105e08_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e08_2023.csv: 2.3122788237935734\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.15250000000000002, 'colsample_bytree': 0.9}\n",
            "\n",
            "Processing file: c05m124e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m124e01_2023.csv: 2.3086936410003682\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c01m045e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m045e01_2022.csv: 2.2997204434355747\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c01m045e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m045e01_2023.csv: 2.5148179816949447\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.105, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c05m124e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m124e01_2022.csv: 2.104846861988057\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m105e08_2021.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e08_2021.csv: 2.161009768427843\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            " Hyperparameter tuning completed for all files!\n",
            "Results saved to: /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Resampled/xgboost_tuning_results_all_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "5q8KmlbdCuZk",
        "outputId": "6fe1e385-8999-4664-a990-4d7eb416edcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       Best Parameters  \\\n",
              "c01m045e01_2021.csv  {'subsample': 0.6, 'n_estimators': 150, 'max_d...   \n",
              "c05m124e01_2021.csv  {'subsample': 0.9, 'n_estimators': 150, 'max_d...   \n",
              "c05m105e08_2022.csv  {'subsample': 0.7, 'n_estimators': 50, 'max_de...   \n",
              "c05m105e08_2023.csv  {'subsample': 0.6, 'n_estimators': 100, 'max_d...   \n",
              "c05m124e01_2023.csv  {'subsample': 0.9, 'n_estimators': 50, 'max_de...   \n",
              "c01m045e01_2022.csv  {'subsample': 0.6, 'n_estimators': 100, 'max_d...   \n",
              "c01m045e01_2023.csv  {'subsample': 0.7, 'n_estimators': 50, 'max_de...   \n",
              "c05m124e01_2022.csv  {'subsample': 0.6, 'n_estimators': 100, 'max_d...   \n",
              "c05m105e08_2021.csv  {'subsample': 0.6, 'n_estimators': 150, 'max_d...   \n",
              "\n",
              "                     Best RMSE  \n",
              "c01m045e01_2021.csv   2.237123  \n",
              "c05m124e01_2021.csv   2.101566  \n",
              "c05m105e08_2022.csv   2.166335  \n",
              "c05m105e08_2023.csv   2.312279  \n",
              "c05m124e01_2023.csv   2.308694  \n",
              "c01m045e01_2022.csv   2.299720  \n",
              "c01m045e01_2023.csv   2.514818  \n",
              "c05m124e01_2022.csv   2.104847  \n",
              "c05m105e08_2021.csv   2.161010  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ab43272-4760-4ea5-9135-a6ca55582036\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Best Parameters</th>\n",
              "      <th>Best RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>c01m045e01_2021.csv</th>\n",
              "      <td>{'subsample': 0.6, 'n_estimators': 150, 'max_d...</td>\n",
              "      <td>2.237123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c05m124e01_2021.csv</th>\n",
              "      <td>{'subsample': 0.9, 'n_estimators': 150, 'max_d...</td>\n",
              "      <td>2.101566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c05m105e08_2022.csv</th>\n",
              "      <td>{'subsample': 0.7, 'n_estimators': 50, 'max_de...</td>\n",
              "      <td>2.166335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c05m105e08_2023.csv</th>\n",
              "      <td>{'subsample': 0.6, 'n_estimators': 100, 'max_d...</td>\n",
              "      <td>2.312279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c05m124e01_2023.csv</th>\n",
              "      <td>{'subsample': 0.9, 'n_estimators': 50, 'max_de...</td>\n",
              "      <td>2.308694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c01m045e01_2022.csv</th>\n",
              "      <td>{'subsample': 0.6, 'n_estimators': 100, 'max_d...</td>\n",
              "      <td>2.299720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c01m045e01_2023.csv</th>\n",
              "      <td>{'subsample': 0.7, 'n_estimators': 50, 'max_de...</td>\n",
              "      <td>2.514818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c05m124e01_2022.csv</th>\n",
              "      <td>{'subsample': 0.6, 'n_estimators': 100, 'max_d...</td>\n",
              "      <td>2.104847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c05m105e08_2021.csv</th>\n",
              "      <td>{'subsample': 0.6, 'n_estimators': 150, 'max_d...</td>\n",
              "      <td>2.161010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ab43272-4760-4ea5-9135-a6ca55582036')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ab43272-4760-4ea5-9135-a6ca55582036 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ab43272-4760-4ea5-9135-a6ca55582036');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed8934a1-b65a-4c04-80d2-bd2f59637bd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed8934a1-b65a-4c04-80d2-bd2f59637bd6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed8934a1-b65a-4c04-80d2-bd2f59637bd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a7012d43-cd25-4dcc-85b5-e9bfec6bf282\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a7012d43-cd25-4dcc-85b5-e9bfec6bf282 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Best Parameters\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13129165615781066,\n        \"min\": 2.1015662056553825,\n        \"max\": 2.5148179816949447,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2.104846861988057,\n          2.1015662056553825,\n          2.2997204434355747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost - 2021 - Parameters selection"
      ],
      "metadata": {
        "id": "eZs3aNi5FiOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Folder containing the CSV files\n",
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Resampled/\"\n",
        "\n",
        "# Hyperparameter distribution for Randomized Search\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': np.linspace(0.01, 0.2, 5),\n",
        "    'subsample': np.linspace(0.6, 1.0, 5),\n",
        "    'colsample_bytree': np.linspace(0.6, 1.0, 5)\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results_dict = {}\n",
        "\n",
        "file_patterns= ['c05m105e08_2021.csv','c05m105e09_2021.csv','c05m041e09_2021.csv','c05m031e04_2021.csv','c05m124e01_2021.csv','c02m026e02_2021.csv',\n",
        "                'c01m045e01_2021.csv','c04m122e01_2021.csv','c01m080e01_2021.csv','c03m093e04_2021.csv', 'c05m050e01_2021.csv','c03m102e01_2021.csv',\n",
        "                'c01m083e01_2021.csv','c05m128e02_2021.csv','c05m040e13_2021.csv','c03m070e01_2021.csv']\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        print(f\"\\nProcessing file: {file_name}\")\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'  # Default year\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value']]\n",
        "\n",
        "\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-01-01') & (data['timestamp'] <= f'{year}-12-30')].reset_index(drop=True)\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered['time_step'] = range(len(data_filtered))\n",
        "        data_filtered['hour'] = data_filtered['timestamp'].dt.hour\n",
        "        data_filtered['minute'] = data_filtered['timestamp'].dt.minute\n",
        "        data_filtered['day_of_week'] = data_filtered['timestamp'].dt.dayofweek\n",
        "        data_filtered['month'] = data_filtered['timestamp'].dt.month\n",
        "\n",
        "        # Define Features and Target\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X = data_filtered[features]\n",
        "        y = data_filtered['temp_value']\n",
        "\n",
        "        # Remove missing target values\n",
        "        X = X.loc[y.notna()]\n",
        "        y = y.loc[y.notna()]\n",
        "\n",
        "        xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "        # Perform RandomizedSearchCV\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=xgb_model,\n",
        "            param_distributions=param_dist,\n",
        "            scoring='neg_root_mean_squared_error',\n",
        "            n_iter=50,\n",
        "            cv=5,\n",
        "            verbose=1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        random_search.fit(X, y)\n",
        "\n",
        "        # Save Best Parameters and RMSE for this file\n",
        "        best_params = random_search.best_params_\n",
        "        best_rmse = np.sqrt(-random_search.best_score_)\n",
        "\n",
        "        results_dict[file_name] = {\n",
        "            \"Best Parameters\": best_params,\n",
        "            \"Best RMSE\": best_rmse\n",
        "        }\n",
        "\n",
        "        print(f\"Best RMSE for {file_name}: {best_rmse}\")\n",
        "        print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Convert results dictionary to DataFrame for better readability\n",
        "results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
        "\n",
        "# Save results to CSV file\n",
        "results_output_path = os.path.join(input_folder_path, \"xgboost_tuning_results_2021.csv\")\n",
        "results_df.to_csv(results_output_path)\n",
        "\n",
        "print(\"\\n Hyperparameter tuning completed for all files!\")\n",
        "print(f\"Results saved to: {results_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qldZqMn2TYn0",
        "outputId": "ee969cf8-441b-40c5-9b29-e7a9aed5b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Hyperparameter tuning completed for all files!\n",
            "Results saved to: /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Resampled/xgboost_tuning_results_2022.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
        "import ast\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Resampled/'\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/'\n",
        "parameter_file = '/content/xgboost_tuning_results_2021.csv'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "# Load hyperparameters\n",
        "xgb_params_df = pd.read_csv(parameter_file)\n",
        "xgb_params_df.rename(columns={'Unnamed: 0': 'station_id'}, inplace=True)\n",
        "\n",
        "xgb_params_df['station_id'] = xgb_params_df['station_id'].astype(str).str.lower()\n",
        "if 'Best Parameters' in xgb_params_df.columns:\n",
        "    xgb_params_df['Best Parameters'] = xgb_params_df['Best Parameters'].apply(ast.literal_eval)\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        station_id = file_name.lower()\n",
        "\n",
        "        # Ensure station_id exists in the hyperparameters file\n",
        "        params_row = xgb_params_df[xgb_params_df['station_id'] == station_id]\n",
        "        if params_row.empty:\n",
        "            print(f\"Skipping {file_name}: No matching hyperparameters found.\")\n",
        "            continue\n",
        "\n",
        "        params = params_row.iloc[0]['Best Parameters']\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value']]\n",
        "\n",
        "        # Feature Engineering\n",
        "        data['time_step'] = range(len(data))\n",
        "        data['hour'] = data['timestamp'].dt.hour\n",
        "        data['minute'] = data['timestamp'].dt.minute\n",
        "        data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "        data['month'] = data['timestamp'].dt.month\n",
        "\n",
        "        # Train XGBoost\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        known_data = data.dropna()\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_known, y_known, test_size=0.2, random_state=42)\n",
        "\n",
        "        xgb_model = XGBRegressor(\n",
        "            n_estimators=int(params.get('n_estimators', 100)),\n",
        "            learning_rate=float(params.get('learning_rate', 0.1)),\n",
        "            max_depth=int(params.get('max_depth', 5)),\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate model performance on the test set\n",
        "        y_pred = xgb_model.predict(X_test)\n",
        "        mse = root_mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"Performance for {file_name} - MSE: {mse:.4f}, R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Predict missing values\n",
        "        missing_data = data[data['temp_value'].isna()]\n",
        "        if not missing_data.empty:\n",
        "            X_missing = missing_data[features]\n",
        "            data.loc[data['temp_value'].isna(), 'temp_value'] = xgb_model.predict(X_missing)\n",
        "\n",
        "        # Saving imputed dataset\n",
        "        output_path = os.path.join(output_folder_path, file_name)\n",
        "        data[['timestamp', 'temp_value']].to_csv(output_path, index=False)\n",
        "        print(f'Processed {file_name} and saved to {output_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slr2lpvfCBLR",
        "outputId": "282e4bf4-e54a-4d76-e28e-158980759c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for c05m105e08_2021.csv - MSE: 2.2386, R2 Score: 0.8809\n",
            "Processed c05m105e08_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m105e08_2021.csv\n",
            "Performance for c05m105e09_2021.csv - MSE: 1.9181, R2 Score: 0.9224\n",
            "Processed c05m105e09_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m105e09_2021.csv\n",
            "Performance for c05m041e09_2021.csv - MSE: 1.0965, R2 Score: 0.9561\n",
            "Processed c05m041e09_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m041e09_2021.csv\n",
            "Skipping c05m028e04_2021.csv: No matching hyperparameters found.\n",
            "Skipping c02m051e03_2021.csv: No matching hyperparameters found.\n",
            "Skipping c01m141e01_2021.csv: No matching hyperparameters found.\n",
            "Performance for c05m031e04_2021.csv - MSE: 1.4435, R2 Score: 0.9446\n",
            "Processed c05m031e04_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m031e04_2021.csv\n",
            "Performance for c05m124e01_2021.csv - MSE: 2.2441, R2 Score: 0.8860\n",
            "Processed c05m124e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m124e01_2021.csv\n",
            "Skipping c03m096e01_2021.csv: No matching hyperparameters found.\n",
            "Performance for c02m026e02_2021.csv - MSE: 1.2759, R2 Score: 0.9655\n",
            "Processed c02m026e02_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c02m026e02_2021.csv\n",
            "Skipping c03m121e01_2021.csv: No matching hyperparameters found.\n",
            "Performance for c01m045e01_2021.csv - MSE: 2.2171, R2 Score: 0.9081\n",
            "Processed c01m045e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c01m045e01_2021.csv\n",
            "Performance for c04m122e01_2021.csv - MSE: 1.2542, R2 Score: 0.9609\n",
            "Processed c04m122e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c04m122e01_2021.csv\n",
            "Skipping c01m127e01_2021.csv: No matching hyperparameters found.\n",
            "Performance for c01m080e01_2021.csv - MSE: 2.5208, R2 Score: 0.8782\n",
            "Processed c01m080e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c01m080e01_2021.csv\n",
            "Skipping c01m061e01_2021.csv: No matching hyperparameters found.\n",
            "Performance for c03m093e04_2021.csv - MSE: 2.4658, R2 Score: 0.8834\n",
            "Processed c03m093e04_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c03m093e04_2021.csv\n",
            "Performance for c05m050e01_2021.csv - MSE: 2.4120, R2 Score: 0.8886\n",
            "Processed c05m050e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m050e01_2021.csv\n",
            "Performance for c03m102e01_2021.csv - MSE: 2.2710, R2 Score: 0.8855\n",
            "Processed c03m102e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c03m102e01_2021.csv\n",
            "Skipping c02m042e02_2021.csv: No matching hyperparameters found.\n",
            "Performance for c01m083e01_2021.csv - MSE: 2.8439, R2 Score: 0.8633\n",
            "Processed c01m083e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c01m083e01_2021.csv\n",
            "Performance for c05m128e02_2021.csv - MSE: 2.0552, R2 Score: 0.8948\n",
            "Processed c05m128e02_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m128e02_2021.csv\n",
            "Performance for c05m040e13_2021.csv - MSE: 1.5938, R2 Score: 0.9281\n",
            "Processed c05m040e13_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c05m040e13_2021.csv\n",
            "Performance for c03m070e01_2021.csv - MSE: 1.8540, R2 Score: 0.9168\n",
            "Processed c03m070e01_2021.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2021/Interpolated XGBoost/c03m070e01_2021.csv\n",
            "Skipping xgboost_tuning_results_2021.csv: No matching hyperparameters found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost - 2022 - Parameters selection"
      ],
      "metadata": {
        "id": "syPcsnmeGHcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2022\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Folder containing the CSV files\n",
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Resampled/\"\n",
        "\n",
        "# Hyperparameter distribution for Randomized Search\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': np.linspace(0.01, 0.2, 5),\n",
        "    'subsample': np.linspace(0.6, 1.0, 5),\n",
        "    'colsample_bytree': np.linspace(0.6, 1.0, 5)\n",
        "}\n",
        "# Dictionary to store results\n",
        "results_dict = {}\n",
        "\n",
        "file_patterns=['c05m105e08_2022.csv','c05m124e01_2022.csv','c05m041e09_2022.csv','c01m083e01_2022.csv','c01m141e01_2022.csv','c05m028e04_2022.csv',\n",
        "               'c05m105e09_2022.csv','c02m042e02_2022.csv','c05m050e01_2022.csv','c01m080e01_2022.csv','c03m121e01_2022.csv','c03m093e04_2022.csv',\n",
        "               'c03m096e01_2022.csv','c01m045e01_2022.csv','c03m102e01_2022.csv','c02m051e03_2022.csv']\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        print(f\"\\nProcessing file: {file_name}\")\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'  # Default year\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value']]\n",
        "\n",
        "        # Adjust the year in the timestamp\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        # Filter the data for the period between June and August\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-01-01') & (data['timestamp'] <= f'{year}-12-30')].reset_index(drop=True)\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered['time_step'] = range(len(data_filtered))\n",
        "        data_filtered['hour'] = data_filtered['timestamp'].dt.hour\n",
        "        data_filtered['minute'] = data_filtered['timestamp'].dt.minute\n",
        "        data_filtered['day_of_week'] = data_filtered['timestamp'].dt.dayofweek\n",
        "        data_filtered['month'] = data_filtered['timestamp'].dt.month\n",
        "\n",
        "        # Define Features and Target\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X = data_filtered[features]\n",
        "        y = data_filtered['temp_value']\n",
        "\n",
        "        # Remove missing target values\n",
        "        X = X.loc[y.notna()]\n",
        "        y = y.loc[y.notna()]\n",
        "\n",
        "        # Initialize XGBoost model\n",
        "        xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "        # Perform RandomizedSearchCV\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=xgb_model,\n",
        "            param_distributions=param_dist,\n",
        "            scoring='neg_root_mean_squared_error',\n",
        "            n_iter=50,\n",
        "            cv=5,\n",
        "            verbose=1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        random_search.fit(X, y)\n",
        "\n",
        "        # Save Best Parameters and RMSE for this file\n",
        "        best_params = random_search.best_params_\n",
        "        best_rmse = np.sqrt(-random_search.best_score_)\n",
        "\n",
        "        results_dict[file_name] = {\n",
        "            \"Best Parameters\": best_params,\n",
        "            \"Best RMSE\": best_rmse\n",
        "        }\n",
        "\n",
        "        print(f\"Best RMSE for {file_name}: {best_rmse}\")\n",
        "        print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Convert results dictionary to DataFrame for better readability\n",
        "results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
        "\n",
        "# Save results to CSV file\n",
        "results_output_path = os.path.join(input_folder_path, \"xgboost_tuning_results_2022.csv\")\n",
        "results_df.to_csv(results_output_path)\n",
        "\n",
        "print(\"\\n Hyperparameter tuning completed for all files!\")\n",
        "print(f\"Results saved to: {results_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx_5WLVmqa5k",
        "outputId": "7ffee2f0-82d8-4a93-80af-8a01229645d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: c05m105e08_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e08_2022.csv: 2.1544369683672735\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c05m124e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m124e01_2022.csv: 2.107354232793785\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m041e09_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m041e09_2022.csv: 1.7575222318545525\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c01m083e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m083e01_2022.csv: 2.3765803132576098\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c01m141e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m141e01_2022.csv: 2.5893338418635126\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m028e04_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m028e04_2022.csv: 1.9776900638013484\n",
            "Best Parameters: {'subsample': 0.8, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m105e09_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e09_2022.csv: 2.141243480130898\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c02m042e02_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c02m042e02_2022.csv: 2.1349938973854763\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m050e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m050e01_2022.csv: 2.2260791597595704\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c01m080e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m080e01_2022.csv: 2.239761706250312\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c03m121e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m121e01_2022.csv: 2.0558698070262422\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c03m093e04_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m093e04_2022.csv: 2.3242018868364984\n",
            "Best Parameters: {'subsample': 0.8, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c03m096e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m096e01_2022.csv: 2.081077627478242\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c01m045e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m045e01_2022.csv: 2.2891133652855773\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c03m102e01_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m102e01_2022.csv: 2.108178507861085\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c02m051e03_2022.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c02m051e03_2022.csv: 2.254823141551116\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            " Hyperparameter tuning completed for all files!\n",
            "Results saved to: /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Resampled/xgboost_tuning_results_2022.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
        "import ast\n",
        "\n",
        "\n",
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Resampled/\"\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/'\n",
        "parameter_file = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Resampled//xgboost_tuning_results_2022.csv'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "# Load hyperparameters\n",
        "xgb_params_df = pd.read_csv(parameter_file)\n",
        "xgb_params_df.rename(columns={'Unnamed: 0': 'station_id'}, inplace=True)\n",
        "\n",
        "xgb_params_df['station_id'] = xgb_params_df['station_id'].astype(str).str.lower()\n",
        "if 'Best Parameters' in xgb_params_df.columns:\n",
        "    xgb_params_df['Best Parameters'] = xgb_params_df['Best Parameters'].apply(ast.literal_eval)\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        station_id = file_name.lower()\n",
        "\n",
        "        # Ensure station_id exists in the hyperparameters file\n",
        "        params_row = xgb_params_df[xgb_params_df['station_id'] == station_id]\n",
        "        if params_row.empty:\n",
        "            print(f\"Skipping {file_name}: No matching hyperparameters found.\")\n",
        "            continue\n",
        "\n",
        "        params = params_row.iloc[0]['Best Parameters']\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value']]\n",
        "\n",
        "        # Feature Engineering\n",
        "        data['time_step'] = range(len(data))\n",
        "        data['hour'] = data['timestamp'].dt.hour\n",
        "        data['minute'] = data['timestamp'].dt.minute\n",
        "        data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "        data['month'] = data['timestamp'].dt.month\n",
        "\n",
        "        # Train XGBoost\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        known_data = data.dropna()\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_known, y_known, test_size=0.2, random_state=42)\n",
        "\n",
        "        xgb_model = XGBRegressor(\n",
        "            n_estimators=int(params.get('n_estimators', 100)),\n",
        "            learning_rate=float(params.get('learning_rate', 0.1)),\n",
        "            max_depth=int(params.get('max_depth', 5)),\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate model performance on the test set\n",
        "        y_pred = xgb_model.predict(X_test)\n",
        "        mse = root_mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"Performance for {file_name} - MSE: {mse:.4f}, R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Predict missing values\n",
        "        missing_data = data[data['temp_value'].isna()]\n",
        "        if not missing_data.empty:\n",
        "            X_missing = missing_data[features]\n",
        "            data.loc[data['temp_value'].isna(), 'temp_value'] = xgb_model.predict(X_missing)\n",
        "\n",
        "        # Saving imputed dataset\n",
        "        output_path = os.path.join(output_folder_path, file_name)\n",
        "        data[['timestamp', 'temp_value']].to_csv(output_path, index=False)\n",
        "        print(f'Processed {file_name} and saved to {output_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678d2567-b09f-4aa7-e602-878d9f65019e",
        "id": "wchYQyCxGHcy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for c05m105e08_2022.csv - MSE: 2.1274, R2 Score: 0.9096\n",
            "Processed c05m105e08_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c05m105e08_2022.csv\n",
            "Skipping c03m070e01_2022.csv: No matching hyperparameters found.\n",
            "Performance for c05m124e01_2022.csv - MSE: 2.2316, R2 Score: 0.9070\n",
            "Processed c05m124e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c05m124e01_2022.csv\n",
            "Skipping c05m040e13_2022.csv: No matching hyperparameters found.\n",
            "Performance for c05m041e09_2022.csv - MSE: 1.4039, R2 Score: 0.9414\n",
            "Processed c05m041e09_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c05m041e09_2022.csv\n",
            "Skipping c01m061e01_2022.csv: No matching hyperparameters found.\n",
            "Performance for c01m083e01_2022.csv - MSE: 3.0667, R2 Score: 0.8568\n",
            "Processed c01m083e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c01m083e01_2022.csv\n",
            "Skipping c02m026e02_2022.csv: No matching hyperparameters found.\n",
            "Skipping c05m128e02_2022.csv: No matching hyperparameters found.\n",
            "Skipping c01m127e01_2022.csv: No matching hyperparameters found.\n",
            "Performance for c01m141e01_2022.csv - MSE: 3.5814, R2 Score: 0.8706\n",
            "Processed c01m141e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c01m141e01_2022.csv\n",
            "Performance for c05m028e04_2022.csv - MSE: 1.6631, R2 Score: 0.9340\n",
            "Processed c05m028e04_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c05m028e04_2022.csv\n",
            "Performance for c05m105e09_2022.csv - MSE: 2.1723, R2 Score: 0.9185\n",
            "Processed c05m105e09_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c05m105e09_2022.csv\n",
            "Performance for c02m042e02_2022.csv - MSE: 2.5659, R2 Score: 0.8774\n",
            "Processed c02m042e02_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c02m042e02_2022.csv\n",
            "Skipping c04m122e01_2022.csv: No matching hyperparameters found.\n",
            "Performance for c05m050e01_2022.csv - MSE: 2.5708, R2 Score: 0.9006\n",
            "Processed c05m050e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c05m050e01_2022.csv\n",
            "Performance for c01m080e01_2022.csv - MSE: 2.6877, R2 Score: 0.8854\n",
            "Processed c01m080e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c01m080e01_2022.csv\n",
            "Performance for c03m121e01_2022.csv - MSE: 2.0870, R2 Score: 0.9111\n",
            "Processed c03m121e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c03m121e01_2022.csv\n",
            "Performance for c03m093e04_2022.csv - MSE: 2.7728, R2 Score: 0.8719\n",
            "Processed c03m093e04_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c03m093e04_2022.csv\n",
            "Performance for c03m096e01_2022.csv - MSE: 2.0259, R2 Score: 0.9119\n",
            "Processed c03m096e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c03m096e01_2022.csv\n",
            "Skipping c05m031e04_2022.csv: No matching hyperparameters found.\n",
            "Performance for c01m045e01_2022.csv - MSE: 2.7750, R2 Score: 0.8803\n",
            "Processed c01m045e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c01m045e01_2022.csv\n",
            "Performance for c03m102e01_2022.csv - MSE: 2.3399, R2 Score: 0.9049\n",
            "Processed c03m102e01_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c03m102e01_2022.csv\n",
            "Performance for c02m051e03_2022.csv - MSE: 2.4141, R2 Score: 0.8970\n",
            "Processed c02m051e03_2022.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2022/Interpolated XGBoost/c02m051e03_2022.csv\n",
            "Skipping xgboost_tuning_results_2022.csv: No matching hyperparameters found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost - 2023 - Parameters selection"
      ],
      "metadata": {
        "id": "Hl1ZIjKlGSFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2023\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Folder containing the CSV files\n",
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Resampled/\"\n",
        "\n",
        "# Hyperparameter distribution for Randomized Search\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': np.linspace(0.01, 0.2, 5),\n",
        "    'subsample': np.linspace(0.6, 1.0, 5),\n",
        "    'colsample_bytree': np.linspace(0.6, 1.0, 5)\n",
        "}\n",
        "# Dictionary to store results\n",
        "results_dict = {}\n",
        "\n",
        "file_patterns= ['c01m045e01_2023.csv','c01m127e01_2023.csv','c01m061e01_2023.csv','c02m042e02_2023.csv','c01m141e01_2023.csv','c03m070e01_2023.csv',\n",
        "                'c02m051e03_2023.csv','c03m096e01_2023.csv','c04m122e01_2023.csv','c03m102e01_2023.csv','c03m093e04_2023.csv','c05m105e09_2023.csv',\n",
        "                'c05m105e08_2023.csv','c05m041e09_2023.csv','c05m040e13_2023.csv','c05m050e01_2023.csv','c05m124e01_2023.csv','c05m128e02_2023.csv']\n",
        "\n",
        "# os.makedirs(output_folder_path, exist_ok=True)\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if any(pattern in file_name for pattern in file_patterns) and file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        print(f\"\\nProcessing file: {file_name}\")\n",
        "        # Determine the year based on the file name\n",
        "        if '_2022' in file_name:\n",
        "            year = '2022'\n",
        "        elif '_2023' in file_name:\n",
        "            year = '2023'\n",
        "        else:\n",
        "            year = '2021'  # Default year\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value']]\n",
        "\n",
        "        # Adjust the year in the timestamp\n",
        "        data['timestamp'] = data['timestamp'].apply(lambda x: x.replace(year=int(year)))\n",
        "        data_filtered = data[(data['timestamp'] >= f'{year}-01-01') & (data['timestamp'] <= f'{year}-12-30')].reset_index(drop=True)\n",
        "\n",
        "        # Feature Engineering: Add time-based features\n",
        "        data_filtered['time_step'] = range(len(data_filtered))\n",
        "        data_filtered['hour'] = data_filtered['timestamp'].dt.hour\n",
        "        data_filtered['minute'] = data_filtered['timestamp'].dt.minute\n",
        "        data_filtered['day_of_week'] = data_filtered['timestamp'].dt.dayofweek\n",
        "        data_filtered['month'] = data_filtered['timestamp'].dt.month\n",
        "\n",
        "        # Define Features and Target\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        X = data_filtered[features]\n",
        "        y = data_filtered['temp_value']\n",
        "\n",
        "        # Remove missing target values\n",
        "        X = X.loc[y.notna()]\n",
        "        y = y.loc[y.notna()]\n",
        "\n",
        "        # Initialize XGBoost model\n",
        "        xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "        # Perform RandomizedSearchCV\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=xgb_model,\n",
        "            param_distributions=param_dist,\n",
        "            scoring='neg_root_mean_squared_error',\n",
        "            n_iter=50,\n",
        "            cv=5,\n",
        "            verbose=1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        random_search.fit(X, y)\n",
        "\n",
        "        # Save Best Parameters and RMSE for this file\n",
        "        best_params = random_search.best_params_\n",
        "        best_rmse = np.sqrt(-random_search.best_score_)\n",
        "\n",
        "        results_dict[file_name] = {\n",
        "            \"Best Parameters\": best_params,\n",
        "            \"Best RMSE\": best_rmse\n",
        "        }\n",
        "\n",
        "        print(f\"Best RMSE for {file_name}: {best_rmse}\")\n",
        "        print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Convert results dictionary to DataFrame for better readability\n",
        "results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
        "\n",
        "# Save results to CSV file\n",
        "results_output_path = os.path.join(input_folder_path, \"xgboost_tuning_results_2023.csv\")\n",
        "results_df.to_csv(results_output_path)\n",
        "\n",
        "print(\"\\n Hyperparameter tuning completed for all files!\")\n",
        "print(f\"Results saved to: {results_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM0kuUQNuOBA",
        "outputId": "7c742549-f3d4-4e2b-b399-db282f9b7af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: c01m045e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m045e01_2023.csv: 2.494295181818207\n",
            "Best Parameters: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.0575, 'colsample_bytree': 0.8}\n",
            "\n",
            "Processing file: c01m127e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m127e01_2023.csv: 2.428973456563194\n",
            "Best Parameters: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c01m061e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m061e01_2023.csv: 2.567069071540638\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c02m042e02_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c02m042e02_2023.csv: 2.266491587883265\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.105, 'colsample_bytree': 0.8}\n",
            "\n",
            "Processing file: c01m141e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c01m141e01_2023.csv: 2.7684125338699097\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.15250000000000002, 'colsample_bytree': 0.9}\n",
            "\n",
            "Processing file: c03m070e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m070e01_2023.csv: 2.25088586365568\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c02m051e03_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c02m051e03_2023.csv: 2.4228329474926404\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.15250000000000002, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c03m096e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m096e01_2023.csv: 2.2225409976589883\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.15250000000000002, 'colsample_bytree': 0.9}\n",
            "\n",
            "Processing file: c04m122e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c04m122e01_2023.csv: 2.281331417878372\n",
            "Best Parameters: {'subsample': 0.9, 'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.105, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c03m102e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m102e01_2023.csv: 2.334699810245415\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c03m093e04_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c03m093e04_2023.csv: 2.495550182933415\n",
            "Best Parameters: {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c05m105e09_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e09_2023.csv: 2.2824288666013715\n",
            "Best Parameters: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0575, 'colsample_bytree': 1.0}\n",
            "\n",
            "Processing file: c05m105e08_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m105e08_2023.csv: 2.3090733903412173\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.15250000000000002, 'colsample_bytree': 0.9}\n",
            "\n",
            "Processing file: c05m041e09_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m041e09_2023.csv: 2.02877630976868\n",
            "Best Parameters: {'subsample': 0.8, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.105, 'colsample_bytree': 0.7}\n",
            "\n",
            "Processing file: c05m040e13_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m040e13_2023.csv: 2.2349707712492015\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.6}\n",
            "\n",
            "Processing file: c05m050e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m050e01_2023.csv: 2.3903601199190785\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.105, 'colsample_bytree': 0.8}\n",
            "\n",
            "Processing file: c05m124e01_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m124e01_2023.csv: 2.2789521567546784\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.105, 'colsample_bytree': 0.8}\n",
            "\n",
            "Processing file: c05m128e02_2023.csv\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best RMSE for c05m128e02_2023.csv: 2.300930642628909\n",
            "Best Parameters: {'subsample': 0.6, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0575, 'colsample_bytree': 0.7}\n",
            "\n",
            " Hyperparameter tuning completed for all files!\n",
            "Results saved to: /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Resampled/xgboost_tuning_results_2023.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
        "import ast\n",
        "\n",
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Resampled/\"\n",
        "output_folder_path = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/'\n",
        "parameter_file = '/content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Resampled/xgboost_tuning_results_2023.csv'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "# Load hyperparameters\n",
        "xgb_params_df = pd.read_csv(parameter_file)\n",
        "xgb_params_df.rename(columns={'Unnamed: 0': 'station_id'}, inplace=True)\n",
        "\n",
        "xgb_params_df['station_id'] = xgb_params_df['station_id'].astype(str).str.lower()\n",
        "if 'Best Parameters' in xgb_params_df.columns:\n",
        "    xgb_params_df['Best Parameters'] = xgb_params_df['Best Parameters'].apply(ast.literal_eval)\n",
        "\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "        station_id = file_name.lower()\n",
        "\n",
        "        # Ensure station_id exists in the hyperparameters file\n",
        "        params_row = xgb_params_df[xgb_params_df['station_id'] == station_id]\n",
        "        if params_row.empty:\n",
        "            print(f\"Skipping {file_name}: No matching hyperparameters found.\")\n",
        "            continue\n",
        "\n",
        "        params = params_row.iloc[0]['Best Parameters']\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data = data[['timestamp', 'temp_value']]\n",
        "\n",
        "        # Feature Engineering\n",
        "        data['time_step'] = range(len(data))\n",
        "        data['hour'] = data['timestamp'].dt.hour\n",
        "        data['minute'] = data['timestamp'].dt.minute\n",
        "        data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "        data['month'] = data['timestamp'].dt.month\n",
        "\n",
        "        # Train XGBoost\n",
        "        features = ['time_step', 'hour', 'minute', 'day_of_week', 'month']\n",
        "        known_data = data.dropna()\n",
        "        X_known = known_data[features]\n",
        "        y_known = known_data['temp_value']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_known, y_known, test_size=0.2, random_state=42)\n",
        "\n",
        "        xgb_model = XGBRegressor(\n",
        "            n_estimators=int(params.get('n_estimators', 100)),\n",
        "            learning_rate=float(params.get('learning_rate', 0.1)),\n",
        "            max_depth=int(params.get('max_depth', 5)),\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate model performance on the test set\n",
        "        y_pred = xgb_model.predict(X_test)\n",
        "        mse = root_mean_squared_error(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"Performance for {file_name} - MSE: {mse:.4f}, R2 Score: {r2:.4f}\")\n",
        "\n",
        "        # Predict missing values\n",
        "        missing_data = data[data['temp_value'].isna()]\n",
        "        if not missing_data.empty:\n",
        "            X_missing = missing_data[features]\n",
        "            data.loc[data['temp_value'].isna(), 'temp_value'] = xgb_model.predict(X_missing)\n",
        "\n",
        "        # Saving imputed dataset\n",
        "        output_path = os.path.join(output_folder_path, file_name)\n",
        "        data[['timestamp', 'temp_value']].to_csv(output_path, index=False)\n",
        "        print(f'Processed {file_name} and saved to {output_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8696281-963e-4b77-edbb-e28feabbfaf1",
        "id": "rZjLD_9EGSFb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for c01m045e01_2023.csv - MSE: 1.2069, R2 Score: 0.9766\n",
            "Processed c01m045e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c01m045e01_2023.csv\n",
            "Skipping c01m080e01_2023.csv: No matching hyperparameters found.\n",
            "Performance for c01m127e01_2023.csv - MSE: 2.1016, R2 Score: 0.9328\n",
            "Processed c01m127e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c01m127e01_2023.csv\n",
            "Performance for c01m061e01_2023.csv - MSE: 3.0363, R2 Score: 0.8909\n",
            "Processed c01m061e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c01m061e01_2023.csv\n",
            "Skipping c01m083e01_2023.csv: No matching hyperparameters found.\n",
            "Performance for c02m042e02_2023.csv - MSE: 2.0941, R2 Score: 0.9124\n",
            "Processed c02m042e02_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c02m042e02_2023.csv\n",
            "Performance for c01m141e01_2023.csv - MSE: 3.2172, R2 Score: 0.8942\n",
            "Processed c01m141e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c01m141e01_2023.csv\n",
            "Skipping c02m026e02_2023.csv: No matching hyperparameters found.\n",
            "Performance for c03m070e01_2023.csv - MSE: 2.3102, R2 Score: 0.8848\n",
            "Processed c03m070e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c03m070e01_2023.csv\n",
            "Performance for c02m051e03_2023.csv - MSE: 1.9332, R2 Score: 0.9299\n",
            "Processed c02m051e03_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c02m051e03_2023.csv\n",
            "Skipping c05m028e04_2023.csv: No matching hyperparameters found.\n",
            "Performance for c03m096e01_2023.csv - MSE: 1.8084, R2 Score: 0.9228\n",
            "Processed c03m096e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c03m096e01_2023.csv\n",
            "Performance for c04m122e01_2023.csv - MSE: 0.7469, R2 Score: 0.9878\n",
            "Processed c04m122e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c04m122e01_2023.csv\n",
            "Performance for c03m102e01_2023.csv - MSE: 2.5164, R2 Score: 0.8849\n",
            "Processed c03m102e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c03m102e01_2023.csv\n",
            "Performance for c03m093e04_2023.csv - MSE: 1.9470, R2 Score: 0.9343\n",
            "Processed c03m093e04_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c03m093e04_2023.csv\n",
            "Skipping c03m121e01_2023.csv: No matching hyperparameters found.\n",
            "Performance for c05m105e09_2023.csv - MSE: 1.9485, R2 Score: 0.9311\n",
            "Processed c05m105e09_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m105e09_2023.csv\n",
            "Performance for c05m105e08_2023.csv - MSE: 1.9650, R2 Score: 0.9109\n",
            "Processed c05m105e08_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m105e08_2023.csv\n",
            "Performance for c05m041e09_2023.csv - MSE: 1.1962, R2 Score: 0.9546\n",
            "Processed c05m041e09_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m041e09_2023.csv\n",
            "Performance for c05m040e13_2023.csv - MSE: 1.9645, R2 Score: 0.9070\n",
            "Processed c05m040e13_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m040e13_2023.csv\n",
            "Skipping c05m031e04_2023.csv: No matching hyperparameters found.\n",
            "Performance for c05m050e01_2023.csv - MSE: 2.1466, R2 Score: 0.9289\n",
            "Processed c05m050e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m050e01_2023.csv\n",
            "Performance for c05m124e01_2023.csv - MSE: 1.7959, R2 Score: 0.9353\n",
            "Processed c05m124e01_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m124e01_2023.csv\n",
            "Performance for c05m128e02_2023.csv - MSE: 2.6139, R2 Score: 0.8508\n",
            "Processed c05m128e02_2023.csv and saved to /content/drive/MyDrive/Colab Notebooks/Data/Avamet/Temperature/2023/Interpolated XGBoost/c05m128e02_2023.csv\n",
            "Skipping xgboost_tuning_results_2023.csv: No matching hyperparameters found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#files with consecutive missing count < 150\n",
        "x150= ['c05m105e08_2021.csv','c05m105e09_2021.csv','c05m041e09_2021.csv','c05m028e04_2021.csv','c01m141e01_2021.csv','c05m031e04_2021.csv',\n",
        "        'c05m124e01_2021.csv','c02m026e02_2021.csv','c01m045e01_2021.csv','c04m122e01_2021.csv','c01m127e01_2021.csv','c01m080e01_2021.csv',\n",
        "        'c03m093e04_2021.csv','c05m050e01_2021.csv','c03m102e01_2021.csv','c02m042e02_2021.csv','c01m083e01_2021.csv','c05m128e02_2021.csv',\n",
        "        'c05m040e13_2021.csv','c03m070e01_2021.csv']\n",
        "\n",
        "#files with consecutive missing count < 50\n",
        "x50=['c05m105e08_2021.csv','c05m105e09_2021.csv','c05m041e09_2021.csv','c05m031e04_2021.csv','c05m124e01_2021.csv','c02m026e02_2021.csv',\n",
        "     'c01m045e01_2021.csv','c04m122e01_2021.csv','c01m080e01_2021.csv','c03m093e04_2021.csv', 'c05m050e01_2021.csv','c03m102e01_2021.csv',\n",
        "     'c01m083e01_2021.csv','c05m128e02_2021.csv','c05m040e13_2021.csv','c03m070e01_2021.csv']"
      ],
      "metadata": {
        "id": "nJdPEGMuQma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#files with consecutive missing count < 150\n",
        "countx=['c05m105e08_2022.csv','c05m124e01_2022.csv','c05m041e09_2022.csv','c01m083e01_2022.csv','c01m141e01_2022.csv','c05m028e04_2022.csv',\n",
        "        'c05m105e09_2022.csv','c02m042e02_2022.csv','c04m122e01_2022.csv','c05m050e01_2022.csv','c01m080e01_2022.csv','c03m121e01_2022.csv',\n",
        "        'c03m093e04_2022.csv','c03m096e01_2022.csv','c05m031e04_2022.csv','c01m045e01_2022.csv','c03m102e01_2022.csv','c02m051e03_2022.csv']\n",
        "\n",
        "#files with consecutive missing count < 50\n",
        "yy=['c05m105e08_2022.csv','c05m124e01_2022.csv','c05m041e09_2022.csv','c01m083e01_2022.csv','c01m141e01_2022.csv','c05m028e04_2022.csv',\n",
        "    'c05m105e09_2022.csv','c02m042e02_2022.csv','c05m050e01_2022.csv','c01m080e01_2022.csv','c03m121e01_2022.csv','c03m093e04_2022.csv',\n",
        "    'c03m096e01_2022.csv','c01m045e01_2022.csv','c03m102e01_2022.csv','c02m051e03_2022.csv']\n"
      ],
      "metadata": {
        "id": "IWILbpn5ULH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#files with consecutive missing count < 150\n",
        "xyz=['c01m045e01_2023.csv','c01m080e01_2023.csv','c01m127e01_2023.csv','c01m061e01_2023.csv','c01m083e01_2023.csv','c02m042e02_2023.csv',\n",
        "     'c01m141e01_2023.csv','c02m026e02_2023.csv','c02m119e02_2023.csv','c03m070e01_2023.csv','c02m051e03_2023.csv','c05m028e04_2023.csv',\n",
        "     'c03m096e01_2023.csv','c04m122e01_2023.csv','c03m102e01_2023.csv','c03m093e04_2023.csv','c05m105e09_2023.csv','c05m105e08_2023.csv',\n",
        "     'c05m041e09_2023.csv','c05m040e13_2023.csv','c05m050e01_2023.csv','c05m124e01_2023.csv','c05m128e02_2023.csv']\n",
        "\n",
        "#files with consecutive missing count < 50\n",
        "abc= ['c01m045e01_2023.csv','c01m127e01_2023.csv','c01m061e01_2023.csv','c02m042e02_2023.csv','c01m141e01_2023.csv','c03m070e01_2023.csv',\n",
        "      'c02m051e03_2023.csv','c03m096e01_2023.csv','c04m122e01_2023.csv','c03m102e01_2023.csv','c03m093e04_2023.csv','c05m105e09_2023.csv',\n",
        "      'c05m105e08_2023.csv','c05m041e09_2023.csv','c05m040e13_2023.csv','c05m050e01_2023.csv','c05m124e01_2023.csv','c05m128e02_2023.csv']\n"
      ],
      "metadata": {
        "id": "PvnXMWjRm9QX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2jZwvLizkrUQ",
        "F3nInzJxc2UA",
        "Blnw307afuzj",
        "9syT2QGr7IaQ"
      ],
      "provenance": [],
      "mount_file_id": "1RtmbTFV53_VcUqN8LcU7hahA3DnhUm97",
      "authorship_tag": "ABX9TyN0OBn2Zk7uHp8LsePULT4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}